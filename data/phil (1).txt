More than 20,000 people died on American roadways from
January to June, the highest total for the first half of any year
since 2006. U.S. road fatalities have risen by more than 10
percent over the past decade, even as they have fallen
across most of the developed world. In the European Union,
whose population is one-third larger than America’s, traffic
deaths dropped by 36 percent between 2010 and 2020, to
18,800. That downward trend is no accident: European
regulators have pushed carmakers to build vehicles that are
safer for pedestrians and cyclists, and governments regularly
adjust road designs after a crash to reduce the likelihood of
recurrence.
But in the United States, the responsibility for road safety
largely falls on the individual sitting behind the wheel, or
riding a bike, or crossing the street. American transportation
departments, law-enforcement agencies, and news outlets
frequently maintain that most crashes—indeed, 94 percent
of them, according to the most widely circulated statistic
are solely due to human error. Blaming the bad decisions of
road users implies that nobody else could have prevented
them. That enables car companies to deflect attention from
their decisions to add heft and height to the SUVs and trucks
that make up an ever-larger portion of vehicle sales, and it
allows traffic engineers to escape scrutiny for dangerous
street designs.
Read: The absurd primacy of the automobile in American life
The recently passed infrastructure bill will encourage some
safety improvements, including technology to prevent drunk
people from operating a car and better crash tests to
address risk to people outside a vehicle. Yet even as the
federal government prepares to shovel out hundreds of
billions of dollars for roadwork, Americans’ fundamental
misconception of traffic deaths as merely a profusion of
individual mistakes will go largely uncorrected.
In 2015, the National Highway Traffic Safety Administration, a
branch of the U.S. Department of Transportation, published
a two-page memo declaring that “the critical reason, which
is the last event in the crash causal chain, was assigned to
the driver in 94% of the crashes.” The memo, which was
based on the NHTSA’s own analysis of crashes, then offered
a key caveat: “Although the critical reason is an important
part of the description of events leading up to the crash, it is
not intended to be interpreted as the cause of the crash.”
To understand what the NHTSA was trying to say, imagine
the following scenario: It’s a foggy day, and the driver of an
SUV is traveling along a road at the posted speed limit of 40
miles per hour. The limit then drops to 25 as the road
approaches a town—but the road’s lanes do not narrow
(which would naturally compel a driver to apply the brakes),
and the lone sign announcing the lower speed limit is
partially obstructed. Oblivious to the change, the driver
keeps traveling at 40. As he enters the town, a pedestrian
crosses the road at an intersection without a stoplight. The
driver strikes the pedestrian.
Read: The pedestrian-death crisis came to my neighborhood
By the federal government’s definition, the “critical reason”
for this hypothetical crash—the last event in the causal chain
—is the error made by the driver who was speeding at the
time of the collision. Almost certainly, the police will hold him
responsible. But that overlooks many other factors: The
foggy weather obscured the driver’s vision; flawed traffic
engineering failed to compel him to slow down as he
approached the intersection; the SUV’s weight made the
force of the impact much greater than a sedan’s would have
been.
The authors of the 2015 NHTSA report were aware of such
contributing factors. But their disclaimer that the “critical
reason” for a crash is not the same as the “cause” has been
largely ignored. Even a page on the agency’s own website
whittles the message down to “94% of serious crashes are
due to human error.”
Seeking to find a single cause for a crash is a fundamentally
flawed approach to road safety, but it underpins much of
American traffic enforcement and crash prevention. After a
collision, police file a report, noting who violated traffic laws
and generally ignoring factors like road and vehicle design.
Insurance companies, too, are structured to hold someone
accountable. Drivers aren’t the only ones who face such
judgments. Following a crash, a pedestrian might be blamed
for crossing a street where there is no crosswalk (even if the
nearest one is a quarter mile away), and a cyclist might be
cited for not wearing a helmet (although a protected bike
lane would have prevented the crash entirely). News stories
reinforce these narratives, with stories limited to the driver
who was speeding or the pedestrian who crossed against
the light.
Indeed, journalists have disseminated the misleading 94
percent line on influential platforms including The Wall Street
Journal, ABC News, and The Washington Post. Research
institutions such as the University of Michigan and the
University of Idaho have done it too. Even former
Transportation Secretary Elaine Chao has helped sow
confusion, as have transportation departments in states
such as Illinois, Utah, and Texas.
“The 94 percent line is a repeated reference at almost every
state [department of transportation] conference I’ve ever
attended,” Jennifer Homendy, the chair of the National
Transportation Safety Board, told me. When the Michigan
DOT spokesman Jeff Cranson speculated in a 2019 podcast
that human error is actually responsible for more than 95
percent of crashes, the Michigan State University
engineering professor Timothy Gates responded, “Yeah, I
would agree with that, there’s very few crashes caused by a
vehicle defect or road defect, a lot of it really is human error.”
That’s a convenient perspective for engineers designing
vehicles and roads.
And if the buck stops with the driver, automakers feel less
pressure to make lifesaving safety features standard across
their models—which many of them do not. Last year,
Consumer Reports found that the average vehicle buyer
would have to pay $2,500 for a blind-spot-detection system.
Pedestrian-detection technology was standard on 13 of the
15 most popular vehicle models—but unavailable on one and
part of a $16,000 optional package on another.
Read: Cars, pedestrians, and the struggle for the future of
downtowns
With responsibility falling on those directly involved in a
crash, it’s unsurprising that so many highway-safety efforts
revolve around education campaigns, assuming that if
people were just more careful, we’d all be okay. Officials at
the NHTSA and state DOTs pour millions of dollars into these
programs, but their benefits seem modest at best. Officials
“see their role as trying to cajole people on the roads to
make smarter decisions,” Seth LaJeunesse, a senior
research associate at the University of North Carolina’s
Highway Safety Research Center, told me. “Wear a seat belt,
don’t be drunk when driving, and signal appropriately. I think
it’s misguided. After all, who’s going to address structural
problems, if it’s just people being stupid out there on the
road?”
For now, the idea that human error causes nearly all crashes
is a useful talking point for the makers of autonomous-
vehicle technology, which supposedly will prevent such
mistakes. Companies including General Motors, Google, and
the start-up Aurora have touted the 94 percent statistic in
promotional materials, press statements, and even SEC
filings. But, as the Carnegie Mellon University engineering
professor Phil Koopman has pointed out, autonomous
systems will make their own errors on the road. He does not
expect AVs to reduce crashes by more than 50 percent,
even in a best-case scenario. And an all-autonomous driving
future is still at least decades away, suggesting that AVs will
not reverse the growing death toll on American roads for
many years to come—if they ever do.
With the infrastructure bill now signed into law, the federal
government has a chance to rethink its approach and
messaging. Dumping the dangerous 94 percent myth would
be a good start; deemphasizing pointless traffic-safety PR
campaigns would help too. Encouraging state and local
transportation agencies—not just law enforcement—to
investigate crashes, which New York City is now doing,
would be even better. What we need most is a reexamination
of how carmakers, traffic engineers, and community
members—as well as the traveling public—together bear
responsibility for saving some of the thousands of lives lost
annually on American roadways. Blaming human error alone
is convenient, but it places all Americans in greater danger.




Page
2
of 20
Ethics and Genetically Modified Foods
GARY COMSTOCK
Iowa State University
Ames, IA
Much of the food consumed in the United States is genetically modified (GM),
i.e. derived from microorganisms, plants, or animals that have been manipu-
lated at the molecular level to provide them with traits that farmers or
consumers desire. These foods often are produced using techniques in which
“foreign” genes are inserted into the microorganisms, plants, or animals.
Foreign genes are those taken from sources other than the organism’s natural
parents. In other words, GM plants contain genes they would not have
contained if researchers had only used traditional plant breeding methods.
Some consumer advocates object to GM foods on ethical grounds, and in
such cases they typically have reasons for their opposition. In scrutinizing their
reasons, we are practicing applied ethics. Applied ethics involves identifying
peoples’ arguments for various conclusions, and then analyzing those
arguments to determine whether they support the conclusions. A critical goal
here is to decide whether an argument is sound. A sound argument is one
in which all of the premises are true and no mistakes have been made in
reasoning.
Ethically justifiable conclusions inevitably rest on two kinds of claims: (a)
empirical claims, or factual assertions about how the world is—claims ideally
based on the best available scientific observations, principles, and theories,
and (b) normative claims, or value-laden assertions about how the world ought
to be—claims ideally based on the best available moral judgments, principles,
and theories.
Is it ethically justifiable to produce genetically modified crops and foods? There
is an objective answer to this question, and we will try here to figure out what
it is. But we must begin with a proper, heavy, dose of epistemic humility,
acknowledging that few ethicists at the moment seem to think that they know
the final answer.
Should the law allow GM foods to be grown and marketed? The answer to this,
and every, public-policy question rests ultimately with us, citizens who will, in
the voting booth and shopping market, decide the answer. To make up our
minds, we will use feelings, intuitions, conscience, and reason. However, as we
citizens are, by and large, not scientists, we must, to one degree or other, rest
our factual understanding of the matter on the opinions of scientific experts.
Therefore, ethical responsibility in the decision devolves heavily upon scientists
engaged in the new GM technology.
ETHICAL R ESPONSIBILITIES OF S CIENTISTS
Science is a communal process devoted to the discovery of knowledge, and to
open and honest communication of knowledge. Its success, therefore, rests on
two different kinds of values.
Epistemological values are those by which scientists determine which
knowledge-claims are better than others. The values include clarity, objectivity,
capacity to explain a range of observations, and ability to generate accurate
predictions. Claims that are internally inconsistent are jettisoned in favor of
claims that are consistent and in accord with established theories. (At times,
anomalous claims turn out to be justifiable, and an established theory is
overthrown, but these occasions are rare in the history of science.) Epistemo-
logical values in science also include: fecundity, the ability to generate useful
new hypotheses; simplicity, the ability to explain observations with the fewest
additional assumptions or qualifications; and elegance.
Personal values, including honesty and responsibility, are a second class of
values that allows scientists to trust their peers’ knowledge-claims. If scientists
are dishonest, untruthful, fraudulent, or excessively self-interested, the free
flow of accurate information so essential to science will be thwarted. If a
scientist plagiarizes the work of others or uses fabricated data, that scientist’s
work will become shrouded in suspicion and otherwise reliable data will not be
trusted. If scientists exploit those who work under them, or discriminate on the
basis of gender, race, class, or age, then the mechanisms of trust and collegiality
under-girding science will be eroded.
The very institution of scientific discovery is supported—indeed, perme-
ated—with values. Scientists have a variety of goals and functions in society, so
it should be no surprise that they face different challenges.
University and government scientists must be scrupulous in giving credit for
their research to all who deserve it, careful not to divulge proprietary
information, and painstaking in maintaining objectivity, especially when funded
by industry. Industry scientists must also maintain the highest standards of
scientific objectivity—a particular challenge since their work may not be
subject to peer-review procedures as strict as those faced by university
scientists. Industry scientists must also be willing to defend results of their
research that are not favorable to their employer’s interests. Scientists employed
by nongovernmental activist organizations face challenges, as well. Their
objectivity must be maintained in the face of an organization’s explicit advocacy
agenda, and in spite of the fact that their research might provide results that
seriously undermine the organization’s fund-raising attempts. All scientists face
the challenges of communicating complex issues to a public that receives them
through media channels that often are not equipped to communicate the
qualifications and uncertainties attached to much scientific information.
At its core, science is an expression of some of our most cherished values.
The public largely trusts scientists, and scientists must in turn act as good
stewards of this trust.
A M ETHOD FOR ADDRESSING ETHICAL ISSUES
Ethical objections to GM typically center on the possibility of harm to persons
or other living things. Harm may or may not be justified by outweighing
benefits. Whether harms are justified is a question that ethicists try to answer
by working methodically through a series of questions1 :
1. What harm is envisaged? To provide an adequate answer to this
question, we must pay attention to how significant the harm or potential
harm may be (severe or trivial?); who the “stakeholders” are (who are
the persons, animals, even ecosystems, that may be harmed?); the extent
to which various stakeholders might be harmed; and the distribution of
harms. The last question directs attention to a critical issue, the issue of
justice and fairness: are those who are at risk of being harmed by the
action in question different from those who may benefit from it?
2. What information do we have? Sound ethical judgments go hand-in-
hand with thorough understanding of the scientific facts. In a given case,
we may need to ask two questions. Is the scientific information about
harm being presented reliably? Is it fact, hearsay, or opinion? And, what
missing information should we have before making the decision?
3. What are the options? In assessing the various courses of action,
emphasize creative problem solving, seeking to find “win-win”
alternatives in which everyone’s interests are protected. Here we must
identify each stakeholder’s objectives; how many methods are available to
achieve those objectives; and what advantages and disadvantages attach
to each?
1 In describing this method, I have drawn on an ethics assessment tool devised by Dr. Courtney
Campbell, Philosophy Department, Oregon State University, and presented at the Oregon State Uni-
versity Bioethics Institute in Corvallis, OR, Summer 1998.
Comstock
4. What ethical principles should guide us? There are at least three secular
ethical traditions:
• Rights theory holds that we ought always to act so that we treat human
beings as autonomous individuals, and not as mere means to an end.
• Utilitarian theory holds that we ought always to act so that we
maximize good consequences and minimize harmful consequences.
• Virtue theory holds that we ought always act as would a just, fair, good
person.
Ethical theorists are divided about which of these three is best. We manage
this uncertainty through the following procedure. Pick one of the three
principles. Using it as a basis, determine its implications for the decision at
hand. Then, adopt a second principle. Determine what it implies for the
decision at hand. Repeat the procedure with the third principle. Should all three
principles converge on the same conclusion, then we have good reasons for
thinking our conclusion morally justifiable.
How do we achieve moral closure? Does the decision we have reached allow
all stakeholders either to participate in the decision or to have their views
represented? If a compromise solution is deemed necessary in order to manage
otherwise intractable differences, has the compromise been reached in way that
has allowed all interested parties to have their interests articulated, understood,
and considered? If so, then the decision may be justifiable on ethical grounds.
There is a difference between consensus and compromise. Consensus means
that the vast majority of people agree about the right answer to a question. If
the group cannot reach a consensus, but must, nevertheless, take some decision
or other, then a compromise position may be necessary. But neither consensus
nor compromise should be confused with the right answer to an ethical
question. It is possible that a society might reach a consensus position that
is unjust. For example, some societies have held that women should not be
allowed to own property. That may be a consensus position, or even a
compromise position, but it should not be confused with the truth of the
matter. Moral closure is a sad fact of life; we sometimes must decide to
undertake some course of action even though we know that, ethically, it
may not be the right decision, all things considered.
ETHICAL ISSUES I NVOLVED IN THE USE OF G ENETIC T ECHNOLOGY
IN AGRICULTURE
Discussions of the ethical dimensions of agricultural biotechnology are
sometimes confused by a conflation of two quite different sorts of objections
to GM technology: intrinsic and extrinsic. It is critical not only that we
distinguish these two classes, but keep them distinct throughout the ensuing
discussion of ethics.
Extrinsic objections focus on the potential harms consequent upon the
adoption of GMOs. Extrinsic objections hold that GM technology should not
be pursued because of its anticipated results. Briefly stated, the extrinsic
objections go as follows. GMOs may have disastrous effects on animals,
ecosystems, and humans. Possible harms to humans include perpetuation of
social inequities in modern agriculture, decreased food security for women
and children on subsistence farms in developing countries, a growing gap
between well capitalized economies in the northern hemisphere and less
capitalized peasant economies in the south, risks to the food security of
future generations, and the promotion of reductionistic and exploitative
science. Potential harms to ecosystems include possible environmental
catastrophe, inevitable narrowing of germplasm diversity, and irreversible loss
or degradation of air, soils, and waters. Potential harms to animals include
unjustified pain to those used in research and production.
These are valid concerns, and nation-states must have in place testing
mechanisms and regulatory agencies to assess the likelihood, scope, and
distribution of potential harms through a rigorous and well funded risk-
assessment procedure. For this reason, I contend that GM technology must
be developed responsibly and with appropriate caution. However, these
extrinsic objections cannot by themselves justify a moratorium, much less
a permanent ban, on GM technology, because they admit the possibility that
the harms may be minimal and outweighed by the benefits. How can one decide
whether the potential harms outweigh potential benefits unless one conducts
the research, field tests, and data analysis necessary to make a scientifically
informed assessment?
In sum, extrinsic objections raise important questions about GMOs, and each
country using GMOs ought to have in place the organizations and research
structures necessary to ensure their safe use.
There is, however, an entirely different sort of objection to GM technology,
which, if it is sound, would indeed justify a permanent ban.
Intrinsic objections allege that the process of making GMOs is objectionable
in itself. This belief is defended in several ways, but almost all of the formula-
tions are related to one central claim—the “unnaturalness objection” (UE):
It is unnatural to genetically engineer plants, animals, and foods.
If UE is true, then we ought not to engage in bioengineering, however
unfortunate may be the consequences of halting the technology. Were a nation
to accept UE as the conclusion of a sound argument, then much agricultural
research would have to be terminated and potentially significant benefits from
the technology sacrificed. A great deal is at stake.
In Vexing Nature? On Ethical Case Against Agricultural Biotechnology, I discuss
fourteen ways in which UE has been defended (Comstock, 2000). For present
purposes, those fourteen objections can be summarized as follows:
Comstock
• To engage in ag biotech is to play God.
• To engage in ag biotech is to invent world-changing technology.
• To engage in ag biotech is illegitimately to cross species boundaries.
• To engage in ag biotech is to commodify life.
Let us consider each claim in turn.
To engage in ag biotech is to play God. In a western theological framework,
humans are creatures, subjects of the Lord of the Universe, and it would be
impious for them to arrogate to themselves roles and powers appropriate only
for the Creator. Shifting genes around between individuals and species is taking
on a task not appropriate for us, subordinate beings. Therefore, to engage in
bioengineering is to play God.
There are several problems with this argument. First, there are different
interpretations of God. Absent the guidance of any specific religious tradition, it
is logically possible that God is a Being who wants to turn over to us all divine
prerogatives; or explicitly wants to turn over to us at least the prerogative of
engineering plants; or who does not care what we do. If God is any of these
beings, then the argument fails because playing God in this instance is not a
bad thing.
The argument seems to assume, however, that God is not like any of the gods
just described. Assume that the orthodox Jewish and Christian view is correct,
that God is the only personal, perfect, necessarily existing, all-loving, all-
knowing, and all-powerful being. In this traditional western theistic view, finite
humans should not aspire to infinite knowledge and power. To the extent that
bioengineering is an attempt to control nature itself, the argument is that
bioengineering is an unacceptable attempt to usurp God’s dominion.
The problem with this argument is that not all traditional Jews and
Christians think that this God would rule out genetic engineering. I am a
practicing evangelical Christian and the chairperson of my local Church
Council. In my tradition, God is thought to endorse creativity, scientific and
technological development, including genetic improvement. Other traditions
have similar views. In the mystical writings of the Jewish Kabbalah, God is
understood as One who expects humans to be co-creators, technicians working
with God to improve the world. At least one Jewish philosopher, Baruch Brody
(personal communication), has suggested that biotechnology may be a vehicle
ordained by God for the perfection of nature.
Personally, I hesitate to think that humans can “perfect” nature. However, I
have become convinced that GM might help humans to rectify some of the
damage we have already done to nature. And I believe God may endorse such
an aim. For humans are made in the divine image. God desires that we exercise
the spark of divinity within us. Inquisitiveness in science is part of our nature.
Creative impulses are not found only in the literary, musical, and plastic arts.
They are part of molecular biology, cellular theory, ecology, and evolutionary
genetics, too. It is unclear why the desire to investigate and manipulate the
chemical bases of life should not be considered as much a manifestation of our
god-like nature as the writing of poetry and the composition of sonatas. As a
way of providing theological content for UE, then, this argument is unsatisfac-
tory because it is ambiguous and contentious.
To engage in ag biotech is to invent world-changing technology, an activity
that should be reserved to God alone. Let us consider this in conjunction with
a similar objection: to engage in ag biotech is to arrogate historically unprece-
dented power to ourselves. The latter argument here is not the strong one, that
biotech gives us divine power, but the more modest one, that it gives us a
power we have not had previously. Also it would be counterintuitive to judge
an action wrong simply because it has never been performed. In this view, it
would have been wrong to prescribe a new herbal remedy for menstrual
cramps, or to administer a new anesthetic. But that seems absurd. More
argumentation is needed to call historically unprecedented actions morally
wrong. What is needed is to know to what extent our new powers will
transform society, whether we have witnessed prior transformations of this
sort, and whether those transitions are morally acceptable.
We do not know how extensive the ag biotech revolution will be, but let us
assume that it will be as dramatic as its greatest proponents assert. Have we ever
witnessed comparable transitions? The change from hunting and gathering to
agriculture was an astonishing transformation. With agriculture came not only
an increase in the number of humans on the globe, but the first appearance of
complex cultural activities: writing, philosophy, government, music, the arts,
and architecture. What sort of power did people arrogate to themselves when
they moved from hunting and gathering to agriculture? The power of
civilization itself (McNeill, 1989).
Ag biotech is often oversold by its proponents. But suppose that they are
right, that it will bring us historically unprecedented powers. Is this a reason
to oppose it? Not if we accept agriculture and its accompanying advances,
for when we accepted agriculture we arrogated to ourselves historically
unprecedented powers.
In sum, these objections are not convincing.
Comstock
I hesitate to think that humans can “perfect” nature.
However, I have become convinced that GM might help
humans to rectify some of the damage we have already
done to nature. And I believe God may endorse such an aim.
To engage in ag biotech is illegitimately to cross species boundaries. The
problems with this argument are both theological and scientific. I will leave
it to others to argue the scientific case that nature gives ample evidence of
generally fluid boundaries between species. The argument assumes that species
boundaries are distinct, rigid and unchanging, whereas, in fact, species now
appear to be messy, plastic, and mutable. To proscribe the crossing of species
borders on the grounds that it is unnatural seems scientifically indefensible.
It is also difficult to see how this objective could be defended on theological
grounds. None of the scriptural writings of the western religions proscribe
genetic engineering, of course, because genetic engineering was undreamt of
at the time the holy books were written. Now, one might argue that such a
proscription may be derived from Jewish or Christian traditions of scriptural
interpretation. Talmudic laws against mixing “kinds,” for example, might be
taken to ground a general prohibition against inserting genes from “unclean”
species into clean species. Here is one way the argument might go: for an
observant Jew to do what scripture proscribes is morally wrong; Jewish oral and
written law proscribe the mixing of kinds (e.g., eating milk and meat from the
same plate; yoking donkeys and oxen together); bioengineering is the mixing
of kinds; therefore, for a Jew to engage in bioengineering is morally wrong.
But this argument fails to show that bioengineering is intrinsically objection-
able in all of its forms for everyone. The argument might prohibit Jews from
engaging in certain kinds of biotechnological activity but not all; it would not
prohibit, for example, the transferring of genes within a species, nor, apparently,
the transfer of genes from one clean species to another clean species. Inciden-
tally, it is worth noting that the Orthodox community has accepted transgenesis
in its food supply. Eighty to ninety percent of cheese produced in the United
States is made using a GM product, chymosin. This cheese has been accepted
as kosher by Orthodox rabbis (Gressel, 1998).
In conclusion, it is difficult to find a persuasive defense for this objection
either on scientific or on religious grounds.
To engage in ag biotech is to commodify life. The argument here is that
genetic engineering treats life in a reductionistic manner, reducing living
organisms to little more than machines. Life is sacred and not to be treated as
a good of commercial value only, to be bought and sold to the highest bidder.
Could we apply this principle uniformly? Would not objecting to the
products of GM technology on these grounds also require that we object to
the products of ordinary agriculture on the same grounds? Is not the very act
of bartering or exchanging crops and animals for cash vivid testimony to the
fact that every culture on earth has engaged in the commodification of life for
centuries? If one accepts commercial trafficking in non-GM wheat and pigs,
then why should we object to commercial trafficking in GM wheat and GM
pigs? Why should it be wrong for us to treat DNA the way we have previously
treated animals, plants, and viruses (Nelkin and Lindee, 1995)?
Although this objection may be true, it is not a sufficient reason to object
to GM technology because our values and economic institutions have long
accepted the commodification of life. Now, one might object that various
religious traditions have never accepted commodification, and that genetic
engineering presents us with an opportunity to resist, to reverse course. Leon
Kass (1988, 1998), for example, has argued that we have gone too far down the
road of dehumanizing ourselves and treating nature as a machine, and that
we should pay attention to our emotional reactions against practices such as
human cloning. Even if we cannot defend these feelings in rational terms, our
revulsion at the very idea of cloning humans should carry great weight. Mary
Midgley (2000) has argued that moving genes across species boundaries is not
only “yukky” but, perhaps, a monstrous idea, a form of playing God.
Kass and Midgley have eloquently defended the relevance of our emotional
reactions to genetic engineering but, as both admit, we cannot simply allow
our emotions to carry the day. As Midgley writes, “Attention to . . . sympathetic
feelings [can stir] up reasoning that [alters] people’s whole world view”
(Midgely, 2000, p. 10). But as much hinges on the reasoning as on the
emotions.
Are the intrinsic objections sound?Are they clear, consistent, and logical?
Do they rely on principles we are willing to apply uniformly to other parts of
our lives? Might they lead to counter-intuitive results?
We hesitate to accept counter-intuitive results because they run counter to
widely-shared considered moral intuitions. If a moral rule or principle leads to
counter-intuitive results, then we have a strong reason to reject it. For example,
consider the following moral principle, which we might call the doctrine of
naïve consequentialism (NC): always improve the welfare of the most people.
Were we to adopt NC, then we would be not only permitted but required to
sacrifice one healthy person if by doing so we could save many others. If six
people need organ transplants (two need kidneys, one needs a liver, one needs
a heart, and two need lungs) then NC instructs us to sacrifice the life of the
healthy person so as to transplant their six organs to the other six. But this
result, that we are obliged to sacrifice innocent people to save strangers, is
wildly counter-intuitive. This result gives us a strong reason to reject NC.
I have argued that the four formulations of the unnaturalness objection
considered above are unsound insofar as they lead to counter-intuitive results.
I do not take this position lightly. Twelve years ago, I wrote an article, The Case
Against bGH (Comstock, 1988), which, I have been told, was one of the first
papers by a philosopher to object to ag biotech on explicitly ethical grounds.
I then wrote a series of other articles objecting to GM herbicide-resistant crops,
transgenic animals, and, indeed, all of agricultural biotechnology (reprinted in
Comstock, 2000). I am acquainted with worries about GM foods. But, for
reasons that include the weakness of the intrinsic objections, I have come to
change my mind. The sympathetic feelings on which my anti-GMO worldview
was based did not survive the stirring up of reasoning.
Comstock
WHY A RE W E CAREFUL WITH GM F OODS?
I do not pretend to know anything like the full answer to this question, but I
would like to be permitted the luxury of brief speculation about it. The reason
we are careful with GM foods may have to do with a natural, completely
understandable, and wholly rational tendency to take precautions with what
goes into our mouths. When we are in good health and happy with the foods
available to us, we have little to gain from experimenting with a new food, and
no reason to take a chance on a potentially unsafe food. We may think of this
disposition as the precautionary response.When faced with two contrasting
opinions about issues related to food safety, consumers place great emphasis on
negative information. The precautionary response is particularly strong when a
consumer sees little to gain from a new food technology. When a given food is
plentiful, it is rational to place extra weight on negative information about any
particular piece of that food.It is rational to do so, as my colleague Dermot
Hayes has pointed out, even when the source of the negative information is
known to be biased.
There are several reasons to take a precautionary approach to new foods.
First, under conditions in which nutritious tasty food is plentiful, we have
nothing to gain from trying a new food if, from our perspective, it is in other
respects identical to our current foods. Suppose, on a rack in front of me, there
are eighteen dozen maple-frosted Krispy Kreme doughnuts, all baked to a
golden brown, all weighing three ounces. If I am invited to take one of them, I
have no reason to favor one over the other. Suppose, however, that a naked man
runs into the room with wild-hair flying behind him yelling that the sky is
falling. He approaches the rack and points at the third doughnut from the left
on the fourth shelf from the bottom and exclaims, “This doughnut will cause
cancer! Avoid it at all costs, or die!” There is no reason to believe this man’s
claim and yet, since there are so many doughnuts freely available, why take a
chance? It is rational to select other doughnuts, since all are alike. Now,
perhaps one of us is a mountain climber who loves taking risks. They might be
tempted to say, “Heck, I’ll try that doughnut.” In order to focus on the right
question here, the risk-takers should ask themselves whether they would select
the tainted doughnut to take home to feed to their two-year-old daughter. Why
impose any risk on your loved ones when there is no reason to do so?
The Krispy Kreme example is meant to suggest that food tainting is both a
powerful and an extraordinarily easy social act. It is powerful because it
virtually determines consumer behavior. It is easy, because the tainter does not
have to offer any evidence of the food’s danger at all. Under conditions of
plentiful food, rational consumers do and should take precautions, avoiding
possibly tainted food no matter how untrustworthy the information source.
Our tendency to take precautions with our food suggests that a single person
with a negative view of GM foods will be much more influential than many
people with a positive view. The following experiment lends credibility to this
hypothesis. In a willingness-to-pay experiment, Hayes and colleagues (in press)
gave eighty-seven primary food shoppers $40 each. Each participant was
assigned to a group ranging in size from a half-dozen to a dozen members. Each
group was then seated at a table at lunch-time and given one pork sandwich. In
the middle of each table was one additional food item, an irradiated pork
sandwich. Each group of participants was given one of three different
treatments: (a) the Pro-irradiation treatment; (b) the Anti-irradiation treatment;
or (c) the Balanced treatment.
Each treatment began with all of the participants at a table receiving the
same, so-called “neutral” description of an irradiated pork sandwich. The
description read, in part:
The United States Food and Drug Administration has recently approved
the use of ionizing radiation to control Trichinella in pork products.
This process results in a 10,000-fold reduction in Trichinella organisms
in meat. The process does not induce measurable radioactivity in food.
After the participants read this description, they would proceed to conduct
a silent bid in order to purchase the right to exchange their non-irradiated
sandwich for the irradiated sandwich. Whoever bid the highest price would be
able to buy the sandwich for the price bid by the second-highest bidder. In
order to provide participants with information about the opinions of the others
at their table so that they could factor this information into their future bids,
the lowest and highest bids of each round were announced before the next
round of bidding began. At the end of the experiment, one of the ten bidding
rounds would be selected at random, and the person bidding the highest
amount in that round would have to pay the second-highest price bid during
that round for the sandwich.
After five rounds of bidding, the second-highest bids in all three groups
settled rather quickly at an equilibrium point, roughly, twenty cents. That is,
someone at every table was willing to pay twenty cents for the irradiated pork
sandwich, but no one in any group would pay more than twenty cents. The
bidding was repeated five times in order to give participants the opportunity
to respond to information they were getting from others at the table, and to
ensure the robustness of the price.
After five rounds of bidding, each group was given additional information.
Group (a), the so-called Pro group, was provided with a description of the
sandwich that read, in part:
Each year, 9,000 people die in the United States from food-borne illness.
Some die from Trichinella in pork. Millions of others suffer short-term
illness. Irradiated pork is a safe and reliable way to eliminate this
pathogen. The process has been used successfully in twenty countries
since 1950.
Comstock
The Pro-group participants were informed that the source of this positive
description was a pro-irradiation food-industry group. After the description was
read, five more rounds of bidding began. The price of the irradiated sandwich
quickly shot upward, reaching sixty cents by the end of round ten. A ceiling
price was not reached, however, as the bids in every round, including the last,
were significantly higher than in the preceding round—the price was still going
up when the experiment was stopped (Figure 1).
After its first five rounds of bidding, Group (b), was provided with a different
description. It read, in part:
In food irradiation, pork is exposed to radioactive materials. It receives
300,000 rads of radiation—the equivalent of thirty million chest X-
rays. This process results in radiolytic products in food. Some radiolytic
products are carcinogens, and linked to birth defects. The process was
developed in the 1950s by the Atomic Energy Commission.
The source of this description was identified to the bidders as “Food and
Water,” an anti-irradiation activist group in England. After Group (b) read this
description, it began five more rounds of bidding. The bid went down, quickly
reaching zero. After the first five rounds produced a value of twenty cents in
Group (b) for the pork sandwich described in a “neutral” way, no one in this
group would pay a penny for the irradiated sandwich described in a “negative”
way. This result obtained even though the description was clearly identified as
coming from an activist, non-scientific group.
After five rounds of bidding on the neutral description, the third group,
Group (c), received both the positive and negative descriptions. One might
expect that this group’s response would be highly variable, with some
participants scared off by the negative description and others discounting it
for its unscientific source. Some participants might be expected to bid nothing
while others would continue to bid highly. However, the price of the sandwich
in the third, so-called Balanced group, also fell quickly. Indeed, the price
reached zero almost as quickly as it did in Group (b), the negative group.
That is, even though the third group had both the neutral and the positive
Figure 1. Effect of information on average bid for irradiated pork
[reprinted from Hayes et al. (in press)].
description in front of them, no one exposed to the negative description would
pay two cents for the irradiated sandwich.
Hayes’ study illuminates the precautionary response, and carries implications
for the GM debate. These implications are that, given neutral or positive
descriptions of GM foods, consumers initially will pay more for them. Given
negative descriptions of GM foods, consumers initially will not pay more for
them. Finally, and this is the surprising result, given both positive and negative
descriptions of GM foods, consumers initially will not pay more for them. Both
sides in the GM food debate should be scrupulous in providing reasons for all
of their claims, especially negative claims.
In a worldwide context, the precautionary response of those facing food
abundance in developed countries may lead us to be insensitive to the
conditions of those in less fortunate situations. Indeed, we may find ourselves
in the following ethical dilemma.
Comstock
For purposes of argument, let us make the following three assumptions, none
of which is implausible. First, assume that GM food is safe. Second, assume that
some GM foods, such as rice enhanced with iron or vitamin A, virus-resistant
cassava, or aluminum-tolerant sweet potato, may be of great potential benefit to
millions of poor children. Third, assume that widespread anti-GM information
and sentiment, no matter how unreliable on scientific grounds, could shut
down the GM infrastructure in the developed world.
Under these assumptions, consider the possibility that by condemning GM
foods in the countries best suited to conduct GM research safely, activists could
bring to a halt the range of money-making GM foods marketed by multina-
tional corporations. This result might be a good or a bad thing. However, an
unintended side-effect would be that the new GM crops mentioned above might
not be forthcoming, assuming that their development and commercialization
depends upon the addressing of fundamental questions in plant science and
molecular biology that will be answered only if research in private industry is
allowed to progress along with that in public research institutions.
Our precautionary response to new food may put us in an uncomfortable
position. On the one hand, we want to tell “both sides” of the GM story, letting
people know both about the benefits and the risks of the technology. On the
other hand, some of the people touting the benefits of the technology make
outlandish claims that it will feed the world while some of the people decrying
In a worldwide context, the precautionary response of
those facing food abundance in developed countries may
lead us to be insensitive to the conditions of those in less
fortunate situations.
the technology make unsupported claims that it will ruin the world. In this
situation, however, those with unsupported negative stories to tell carry greater
weight than those with unsupported positive stories. Our precautionary
response, then, may well lead, in the short term at least, to the rejection of GM
technology. Yet, this rejection could indirectly harm those children most in
need.
Are we being forced to choose between two fundamental values, the value of
free speech versus the value of children’s lives?
On the one hand, open conversation and transparent decision-making
processes are critical to the foundations of a liberal democratic society. We must
reach out to include everyone in the debate, and allow people to state their
opinions about GM foods, whatever those opinions happen to be, whatever the
level of acquaintance with the science and technology happens to be. Free
speech is a value not to be compromised lightly.
On the other hand, simply stating negative opinions about GM food can
clearly have a tainting effect, a powerful and extraordinarily easy consequence
of free speech. Tainting the technology might result in the loss of this
potentially useful tool. Should we, then, draw some boundaries around the
conversation, insisting that each contributor bring some measure of scientific
data to the table, especially when negative claims are being made? Or are we
collectively prepared to leave the conversation wide open? That is, in the name
of protecting free speech, are we prepared to risk losing an opportunity to help
some of the world’s most vulnerable?
RELIGION AND ETHICS
Religious traditions provide an answer to the question, “How, overall, should
I live my life?” Secular ethical traditions provide an answer to the question,
“What is the right thing to do?” When in a pluralistic society a particular
religion’s answers come into genuine conflict with the answers arrived at
through secular ethical deliberation, we must ask how deep is the conflict.
If the conflict is so deep that honoring the religion’s views would entail
dishonoring another religion’s views, then we have a difficult decision to make.
In such cases, the conclusions of secular ethical deliberation must over-ride
the answers of the religion in question. The reason is that granting privileged
status to one religion will inevitably discriminate against another religion.
Individuals must be allowed to follow their conscience in matters theological.
But if one religion is allowed to enforce its values on others in a way that
restricts the others’ ability to pursue their values, then individual religious
freedom has not been protected.
Moral theorists refer to this feature of nonreligious ethical deliberation as the
overridingness of ethics. If a parent refuses a lifesaving medical procedure for a
minor child on religious grounds, the state is justified in overriding the parent’s
religious beliefs in order to protect what secular ethics regards as a value higher
than religious freedom: the life of a child.
The overridingness of ethics applies to our discussion only if a religious
group claims the right to halt GM technology on purely religious grounds. The
problem here is the confessional problem, of one group attempting to enforce
its beliefs on others. I mean no disrespect to religion; as I have noted, I am a
religious person, and I value religious traditions other than my own. Religious
traditions have been the repositories and incubators of virtuous behavior. Yet
each of our traditions must in a global society learn to coexist peacefully with
competing religions, and with nonreligious traditions and institutions.
If someone objects to GM technology on purely religious grounds, we must
ask on what authority they speak for their tradition, whether there are other,
conflicting, views within their tradition, and whether acting on their views will
entail disrespecting the views of people from other religions. It is, of course, the
right of each tradition to decide its attitude about genetic engineering. But in
the absence of other good reasons, we must not allow someone to ban GM
technology for narrowly sectarian reasons alone. To allow such an action would
be to disrespect the views of people who believe, on equally sincere religious
grounds, that GM technology is not necessarily inconsistent with God’s desires
for us.
MINORITY V IEWS
When, in a pluralistic society, the views of a particular minority come into
genuine conflict with the views of the majority, we must ask a number of
questions. How deep is the conflict? How has the minority been treated in the
past? If the minority has been exploited, have reparations been made? If the
conflict is so deep that honoring the minority’s views would entail overriding
the majority’s views, then we have a difficult decision to make. In such cases,
the conclusions of the state must be just, taking into account the question of
past exploitation and subsequent reparations, or lack thereof. This is a question
of justice.
The question of justice would arise in the discussion of GM technology if the
majority favored GM technology while the minority claimed the right to halt
GM technology. If the minority cited religious arguments to halt GMOs, yet the
majority believed that halting GMOs would result in loss of human life, then
the state faces a decision very similar to the one discussed in the prior section.
In this case, secular policy decisions may be justified in overriding the
minority’s religious arguments insofar as society deems that human life has a
value higher than that of religious freedom.
However, should the minority cite past oppression as the reason that their
values ought to predominate over the majority’s, then a different question
must be addressed. Here, the relevant issues have to do with the nature of past
exploitation, its scope and depth, and the sufficiency of efforts—if there have
there been any—to rectify the injustice and compensate victims. If the problem
is long-standing and has not been addressed, then imposing the will of the
majority would seem a sign of an unjust society insensitive to its past misdeeds.
Comstock
If, on the other hand, the problem has been carefully addressed by both sides
and, for example, just treaties—arrived at through fair procedures and
enforced—are rectifying past wrongs and are preventing new forms of
exploitation, then the minority’s arguments would seem to be far weaker.
This conclusion would be especially compelling if it could be shown that the
lives of other disadvantaged peoples might be put at risk by honoring a
particular minority’s wish to ban GMOs.
CONCLUSION
Earlier I described a method for reaching ethically sound judgments. On the
basis of that method I personally came to change my mind about the moral
acceptability of GM crops. My opinion changed as I took full account of three
considerations: (a) the rights of people in various countries to choose to adopt
GM technology (a consideration falling under the human rights principle);
(b) the balance of likely benefits over harms to consumers and the environment
from GM technology (a utilitarian consideration); and (c) the wisdom of
encouraging discovery, innovation, and careful regulation of GM technology
(a consideration related to virtue theory).
Is it ethically justifiable to pursue genetically modified crops and foods? I have
come to believe that three of our most influential ethical traditions converge on
a common answer. Assuming we proceed responsibly and with appropriate
caution, the answer is yes.
A CKNOWLEDGMENTS
I learned much from discussing these ideas with several colleagues, including
Gary Varner, Tony Smith, Ned Hettinger, Marc Saner, Rob Streiffer, Dermot
Hayes, Kristen Hessler, Fred Kirschenmann, and C.S. Prakash. I was also
fortunate to participate in several conversations on the topic during the past
few months, and would like to express gratitude to my hosts, including:
• Three local chapters of the American Chemical Society at: Eastern Oregon
University (Richard Hermens); Washington State University (Roger
Willett); and Seattle University (Susan Jackels), in October 2000.
• The “New Zealand Royal Commission on Genetic Modification”; a public
audience in Wellington, New Zealand (sponsored by the New Zealand Life
Sciences Network, and Francis Wevers); and St. John’s College, Auckland,
NZ (Graham Redding), November 2000.
• The “Plant Sciences Institute Colloquium,” Iowa State University, February
2001 (Stephen Howell).
• “Biotech Issues 2001,” an Extension In-Service conference at Colorado
State University (Bob Zimdahl and Pat Kendall); and a seminar in the CSU
Philosophy Department (Phil Cafaro and Holmes Rolston); both in
February.
• The 2001 Annual Meeting of the American Association for the Advance-
ment of Science, San Francisco, in February (Katherine R. Smith and
Nicole Ballenger).
• A seminar at the Center for International Development and Science, the
Technology and Public Policy Program, and the Belfer Center for Science
and International Affairs, Harvard University, March, 2001 (Calestous
Juma and Derya Honca).
• The Center for Judaism and the Environment, and Center for Business
Ethics, Jerusalem College for Technology, Israel (Akiva Wolff, Pinchas
Rosenstein, and Jacqueline Rose); and “Symposium 2001: Plant Biotech-
nology, Its Benefits Versus Its Risks,” Tel Aviv University, Israel, May 2001
(Bernie Epel and Roger Beachy).
“Ethical Issues Involved in the Use of Genetic Technology in Agriculture” is
reprinted from pp. 182–195 of Comstock (2000), with the kind permission of
the publisher.
Other portions of the paper were written with support of the Cooperative
State Research, Education, and Extension Service, U.S. Department of
Agriculture, under Agreement No. 00-52100-9617.
REFERENCES AND NOTES
Comstock G (1988) The case against bGH. Agriculture Human Values 5 36–52.
Comstock G (2000) Vexing Nature? On the Ethical Case against Agricultural
Biotechnology. Boston/Dordrecht: Kluwer Academic Publishers.
Gressel J (1998) Observation at the annual meeting of the Weed Science Society
of America Chicago 10 February.
Hayes D et al. (in press) Consumer preferences for food irradiation: how
favorable and unfavorable descriptions affect preferences for irradiated pork
in experimental auctions. Journal of Risk and Uncertainty.
Kass L (1988) Toward a More Natural Science: Biology and Human Affairs. New
York: The Free Press.
Kass L (1998) Beyond biology: Will advances in genetic technology threaten to
dehumanize us all? The New York Times on the Web, August 23, http://
www.nytimes.com/books/98/08/ 23/reviews/980823.23kassct.html.
McNeill W (1989) Gains and losses: an historical perspective on farming. The
1989 Iowa Humanities Lecture (National Endowment for the Humanities and
Iowa Humanities Board, Oakdale Campus, Iowa City, IA, 1989), p 5.
Midgley M (2000) Biotechnology and Monstrosity: Why We Should Pay
Attention to the ‘Yuk Factor.’ Hastings Center Report 30 no. 5, 7–15.
Nelkin D Lindee MS (1995) The DNA Mystique: The Gene as Cultural Icon.
New York: Freeman.
Comstock
Q: I have a background as an ethicist, and I have yet to hear an ethical
principle enunciated clearly, such that it has clear practical implications that are
not subject to some clear counter example. Exactly how seriously should we
take the claim that intrinsic objections are really supposed to provide an
absolute bedrock for morality, as opposed to just one of the many values we
have to take into account and balance with lots of other values?
A: As I understand it, your question is exploring a defense of the
intrinsic objections along the following lines—look, no one bases their
objections to GMOs just on the fact that they think it is playing God, or just on
the fact that it is tinkering with nature. Rather, all of these go together to form a
package, and the cumulative result of worrying about all of them is the basis of
their view. Is that close enough?
Q: Something like that. But also, just from an epistemological or an
ethical perspective, we don’t know yet of any fundamental ethical theory that
is not counter-intuitive. So, isn’t your method going to basically prove that all
ethical principles are wrong, if your method is correct? Take one of the
principles that you enunciated at the end. Ensure that all stakeholders are
heard—do you really want to endorse that as stated, that every single
stakeholder has to be heard? We are going to be sitting around for thousands
of years waiting for everybody to finish.
A: Yes, it’s a good question. Let me answer the one that I articulated
before, then I’ll try to respond to that one. It is appealing to me to think that
the whole is greater than the sum of the parts, but I just don’t think that is true.
In this case, what we have to do, if we want to think responsibly about these
objections, is to look at each one. And if each one turns out to be radically
counter-intuitive then the whole is less than the sum of the parts. On the
question of whether we have any principles that don’t lead to counter-intuitive
results, I am much more optimistic than you are about that. I agree that ethical
theorists haven’t yet articulated such a theory, but, in terms of secular ethics,
we haven’t been at it very long—less than three or four decades by my
reckoning—and I think we will get closer to it than you seem to think. And
finally, notice that these really aren’t ethical principles that lead to counter-
intuitive results, they are more like rules of thumb—how shall we act in this
or that case—and there you are probably right, that we can find a counter
example to any such rule of thumb. But I am less certain that real principles
are subject to defeat so easily.
Q: I think it is fair to say that at least some critics do take their
principles to be absolute, in the sense that they think that saying that suffices
to show that these things are wrong. And so, if you do get a single counter
example, then I think that does cause trouble for them. I think I agree with
you on that point.
A: I am impressed, by the way, by how quickly critics run from these
principles. That is, once they are enunciated—I have had this happen to me—
someone always stands up and says, “That’s not why we are opposed to GMOs!”
And I say, “Okay, good. What are the reasons?” And then they typically turn to
the ones that NABC addresses in depth—safety, environmental consequences,
and so on—which is where the attention should be, in my view.
Q: As I understood your talk, you said that you have changed your
view, from being more anti to pro genetically engineered crops. When you held
your previous view, was it based in any way on these intrinsic objections, or
was it solely based on extrinsic considerations of the risks and benefits?
A: I think I had the intrinsic objections in the back of my mind. But,
in my writings, my objections were typically more consequentialist. I was
concerned about the effects of the new technology on family farmers,
primarily—extrinsic concerns about economic and social dislocating effects.
I was concerned about animal welfare, and still am; that’s an extrinsic concern.
Does that address your question?
Q: Yes. I was curious if it was based on an intrinsic one, what changed
your mind on that. It sounds like what changed your mind was a broader look
at the technology and its potential benefits. I wanted to confirm that.
A: Yes, thank you.
Q: Your previous writings, when you were an opponent of biotechnol-
ogy, have been used by people to back up their beliefs. Now that you have
changed your views, do you have to become more of an activist for the other
side? Or do I have to read the book?
A: Reading the book is a good start! Given the consequences of
negative information that I just showed you, I have a duty now to be as active
for my current views as I used to be for my old views. Which is why I try to
get out as much as I can, and talk.
Q: I appreciate the talk. But you leave nothing of nature standing.
People want to distinguish between the natural and the unnatural, and one way
they do it is to talk about species boundaries. And your entire argument against
those who would not cross species boundaries is, “That would rule out mules.”
So be it. I’ll accept that consequence. But the more important question: is there
any way we can use the concept, or the idea of nature and the natural, in ethical
or esthetic discourse, if we accept biotechnology as natural? And if we don’t
accept it as natural, then it would seem that the people who criticize it on the
grounds that it is against nature may be right.
A: The questioner, Mark Sagoff, has done more than perhaps anyone in
the world to think about what is natural and unnatural, so I hesitate to try to
respond quickly. I do have arguments to offer other than if you accept mules
you must accept GMOs, which I didn’t have time to go through. But, in general,
I am very skeptical about the natural/unnatural distinction. I don’t think it will
Comstock
cut much ice in the end, once we try to sort out what is natural and what is
unnatural. There are so many different places to cut the joints. In the end, there
are better conceptual categories to use, such as sentient or non-sentient, living
or non-living, humanly influenced or not humanly influenced, wild or
domesticated, and those, I suspect, in the long run will get us further faster.
And I learned that from Mark.




Page
1
of 11
The Ones Who Stay and Fight
It’s the Day of Good Birds in the city of Um-Helat! The Day is a local custom,
silly and random as so many local customs can be, and yet beautiful by the
same token. It has little to do with birds—a fact about which locals cheerfully
laugh, because that, too, is how local customs work. It is a day of fluttering
and flight regardless, where pennants of brightly dyed silk plume forth from
every window, and delicate drones of copperwire and featherglass—made
for this day, and flown on no other!—waft and buzz on the wind. Even the
monorail cars trail stylized flamingo feathers from their rooftops, although
these are made of featherglass, too, since real flamingos do not fly at the
speed of sound.
Um-Helat sits at the confluence of three rivers and an ocean. This places it
within the migratory path of several species of butterfly and hummingbird as
they travel north to south and back again. At the Day’s dawning, the children
of the city come forth, most wearing wings made for them by parents and
kind old aunties. (Not all aunties are actually aunties, but in Um-Helat,
anyone can earn auntie-hood. This is a city where numberless aspirations
can be fulfilled.) Some wings are organza stitched onto school backpacks;
some are quilted cotton stuffed with dried flowers and clipped to jacket
shoulders. Some few have been carefully glued together from dozens of
butterflies’ discarded wings—but only those butterflies that died naturally, of
course. Thus adorned, children who can run through the streets do so,
leaping off curbs and making whooshing sounds as they pretend to fly.
Those who cannot run instead ride special drones, belted and barred and
double-checked for safety, which gently bounce them into the air. It’s only a
few feet, though it feels like the height of the sky.
But this is no awkward dystopia, where all are forced to conform. Adults who
refuse to give up their childhood joys wear wings, too, though theirs tend to
be more abstractly constructed. (Some are invisible.) And those who follow
faiths which forbid the emulation of beasts, or those who simply do not want
wings, need not wear them. They are all honored for this choice, as much as
the soarers and flutterers themselves—for without contrasts, how does one
appreciate the different forms that joy can take?
Oh, and there is such joy here, friend. Street vendors sell tiny custard-filled
cakes shaped like jewel beetles, and people who’ve waited all year wolf them
down while sucking air to cool their tongues. Artisans offer cleverly
mechanized paper hummingbirds for passersby to throw; the best ones blur
as they glide. As the afternoon of the Day grows long, Um-Helat’s farmers
arrive, invited as always to be honored alongside the city’s merchants and
technologers. By all three groups’ efforts does the city prosper—but when
aquifers and rivers dip too low, the farmers move to other lands and farm
there, or change from corn-husking to rice-paddying and fishery-feeding.
The management of soil and water and chemistry are intricate arts, as you
know, but here they have been perfected. Here in Um-Helat there is no
hunger: not among the people, and not for the migrating birds and
butterflies when they dip down for a taste of savory nectar. And so farmers
are particularly celebrated on the Day of Good Birds.
The parade wends through the city, farmers ducking their gazes or laughing
as their fellow citizens offer salute. Here is a portly woman, waving a hat of
chicken feathers that someone has gifted her. There is a reedy man in a
coverall, nervously plucking at the brooch he bears, carved and lacquered to
look like a ladybug. He has made it himself, and hopes others will think it
fine. They do!
And here! This woman, tall and strong and bare of arm, her sleek brown
scalp dotted with implanted silver studs, wearing a fine uniform of
stormcloud damask. See how she moves through the crowd, grinning with
them, helping up a child who has fallen. She encourages their cheers and
their delight, speaking to this person in one language and that person in
another. (Um-Helat is a city of polyglots.) She reaches the front of the crowd
and immediately spies the reedy man’s ladybug, whereupon with delighted
eyes and smile, she makes much of it. She points, and others see it, too,
which makes the reedy man blush terribly. But there is only kindness and
genuine pleasure in the smiles, and gradually the reedy man stands a little
taller, walks with a wider stride. He has made his fellow citizens happier, and
there is no finer virtue by the customs of this gentle, rich land.
The slanting afternoon sun stretches golden over the city, reflected light
sparkling along its mica-flecked walls and laser-faceted embossings. A
breeze blows up from the sea, tasting of brine and minerals, so fresh that a
spontaneous cheer wafts along the crowded parade route. Young men by
the waterfront, busily stirring great vats of spiced mussels and pans of rice
and peas and shrimp, cook faster, for it is said in Um-Helat that the smell of
the sea wakes up the belly. Young women on streetcorners bring out sitars
and synthesizers and big wooden drums, the better to get the crowd
dancing the young men’s way. When people stop, too hot or thirsty to
continue, there are glasses of fresh tamarind-lime juice. Elders staff the
shops that sell this, though they also give away the juice if a person is much
in need. There are always souls needing drumbeats and tamarind, in Um-
Helat.
Joyous! It is a steady joy that fills this city, easy to speak of—but ah, though I
have tried, it is most difficult to describe accurately. I see the incredulity in
your face! The difficulty lies partly in my lack of words, and partly in your lack
of understanding, because you have never seen a place like Um-Helat, and
because I am myself only an observer, not yet privileged to visit. Thus I must
try harder to describe it so that you might embrace it, too.
How can I illuminate the people of Um-Helat? You have seen how they love
their children, and how they honor honest, clever labor. You have perhaps
noted their many elders, for I have mentioned them in passing. In Um-Helat,
people live long and richly, with good health for as long as fate and choice
and medicine permits. Every child knows opportunity; every parent has a life.
There are some who go without housing, but they can have an apartment if
they wish. Here where the spaces under bridges are swept daily and
benches have light padding for comfort, they do not live badly. If these
itinerant folk dwell also in delusions, they are kept from weapons or places
that might do them harm; where they risk disease or injury, they are
prevented—or cared for, if matters get out of hand. (We shall speak more of
the caretakers soon.)
And so this is Um-Helat: a city whose inhabitants, simply, care for one
another. That is a city’s purpose, they believe—not merely to generate
revenue or energy or products, but to shelter and nurture the people who do
these things.
What have I forgotten to mention? Oh, it is the thing that will seem most
fantastic to you, friend: the variety! The citizens of Um-Helat are so many
and so wildly different in appearance and origin and development. People in
this land come from many others, and it shows in sheen of skin and kink of
hair and plumpness of lip and hip. If one wanders the streets where the
workers and artisans do their work, there are slightly more people with dark
skin; if one strolls the corridors of the executive tower, there are a few extra
done in pale. There is history rather than malice in this, and it is still being
actively, intentionally corrected—because the people of Um-Helat are not
naive believers in good intentions as the solution to all ills. No, there are no
worshippers of mere tolerance here, nor desperate grovelers for that
grudging pittance of respect which is diversity. Um-Helatians are learned
enough to understand what must be done to make the world better, and
pragmatic enough to actually enact it.
Does that seem wrong to you? It should not. The trouble is that we have a
bad habit, encouraged by those concealing ill intent, of insisting that people
already suffering should be afflicted with further, unnecessary pain. This is
the paradox of tolerance, the treason of free speech: We hesitate to admit
that some people are just fucking evil and need to be stopped.
This is Um-Helat, after all, and not that barbaric America. This is not Omelas,
a tick of a city, fat and happy with its head buried in a tortured child. My
accounting of Um-Helat is an homage, true, but there’s nothing for you to
fear, friend.
And so how does Um-Helat exist? How can such a city possibly survive, let
alone thrive? Wealthy with no poor, advanced with no war, a beautiful place
where all souls know themselves beautiful . . . It cannot be, you say. Utopia?
How banal. It’s a fairy tale, a thought exercise. Crabs in a barrel, dog-eat-
dog, oppression Olympics—it would not last, you insist. It could never be in
the first place. Racism is natural, so natural that we will call it “tribalism” to
insinuate that everyone does it. Sexism is natural and homophobia is natural
and religious intolerance is natural and greed is natural and cruelty is natural
and savagery and fear and and and . . . and. “Impossible!” you hiss, your fists
slowly clenching at your sides. “How dare you. What have these people done
to make you believe such lies? What are you doing to me, to suggest that it is
possible? How dare you. How dare you.”
Oh, friend! I fear I have offended. My apologies.
Yet . . . how else can I convey Um-Helat to you, when even the thought of a
happy, just society raises your ire so? Though I confess I am puzzled as
to why you are so angry. It’s almost as if you feel threatened by the very idea
of equality. Almost as if some part of you needs to be angry. Needs
unhappiness and injustice. But . . . do you?
Do you?
Do you believe, friend? Do you accept the Day of Good Birds, the city, the
joy? No? Then let me tell you one more thing.
Remember the woman? So tall and brown, so handsome and bald, so loving
in her honest pleasure, so fine in her stormcloud gray. She is one of many
wearing the same garb, committed to the same purpose. Follow her, now, as
she leaves behind the crowd and walks along the biofiber-paved side streets
into the shadows. Beneath a skyscraper that floats a few meters off the
ground—oh, it is perfectly safe, Um-Helat has controlled gravity for
generations now—she stops. There two others await: one gethen, one male,
both clad in gray damask, too. They are also bald, their studded heads a-
gleam. They greet each other warmly, with hugs where those are welcomed.
They are no one special. Just some of the many people who work to ensure
the happiness and prosperity of their fellow citizens. Think of them as social
workers if you like; their role is no different from that of social workers
anywhere. Word has come of a troubling case, and this is why they gather: to
discuss it, and make a difficult decision.
There are wonders far greater than a few floating skyscrapers in Um-Helat,
you see, and one of these is the ability to bridge the distances between
possibilities—what we would call universes. Anyone can do it, but almost no
one tries. That is because, due to a quirk of spacetime, the only world that
people in Um-Helat can reach is our own. And why would anyone from this
glorious place want to come anywhere near our benighted hellscape?
Again you seem offended. Ah, friend! You have no right to be.
In any case, there’s little danger of travel. Even Um-Helat has not
successfully found a way to reduce the tremendous energy demands of
macro-scale planar transversal. Only wave particles can move from our
world to theirs, and back again. Only information. Who would bother? Ah, but
you forget: This is a land where no one hungers, no one is left ill, no one lives
in fear, and even war is almost forgotten. In such a place, buoyed by the
luxury of safety and comfort, people may seek knowledge solely for
knowledge’s sake.
But some knowledge is dangerous.
Um-Helat has been a worse place, after all, in its past. Not all of its peoples,
so disparate in origin and custom and language, came together entirely by
choice. The city had a different civilization once—one which might not have
upset you so! (Poor thing. There, there.) Remnants of that time dot the land
all around the city, ruined and enormous and half-broken. Here a bridge.
There a great truck, on its back a rusting, curve-sided thing that ancient
peoples referred to by the exotic term missile. In the distance: the skeletal
remains of another city, once just as vast as Um-Helat, but never so lovely.
Works such as these encumber all the land, no more and no less venerable
to the Um-Helatians than the rest of the landscape. Indeed, every young
citizen must be reminded of these things upon coming of age, and told
carefully curated stories of their nature and purpose. When the young
citizens learn this, it is a shock almost incomprehensible, in that they literally
lack the words to comprehend such things. The languages spoken in Um-
Helat were once our languages, yes—for this world was once our world; it
was not so much parallel as the same, back then. You might still recognize
the languages, but what would puzzle you is how they speak . . . and how
they don’t. Oh, some of this will be familiar to you in concept at least, like
terms for gender that mean neither he nor she, and the condemnation of
words meant to slur and denigrate. And yet you will puzzle over the Um-
Helatians’ choice to retain descriptive terms for themselves like kinky-
haired or fat or deaf. But these are just words, friend, don’t you see? Without
the attached contempt, such terms have no more meaning than if horses
could proudly introduce themselves as palomino or miniature or hairy-
footed. Difference was never the problem in and of itself—and Um-Helatians
still have differences with each other, of opinion and otherwise. Of course
they do! They’re people. But what shocks the young citizens of Um-Helat is
the realization that, once, those differences of opinion involved differences in
respect. That once, value was ascribed to some people, and not others. That
once, humanity was acknowledged for some, and not others.
It’s the Day of Good Birds in Um-Helat, where every soul matters, and even
the idea that some might not is anathema.
This, then, is why the social workers of Um-Helat have come together:
because someone has breached the barrier between worlds. A citizen of
Um-Helat has listened, on equipment you would not recognize but which
records minute quantum perturbations excited by signal wavelengths, to our
radio. He has watched our television. He has followed our social media,
played our videos, liked our selfies. We are remarkably primitive, compared
to Um-Helat. Time flows the same in both worlds, but people there have not
wasted themselves on crushing one another into submission, and this makes
a remarkable difference. So anyone can do it—build a thing to traverse the
worlds. Like building your own ham radio. Easy. Which is why there is an
entire underground industry in Um-Helat—ah! crime! now you believe a little
more—built around information gleaned from the strange alien world that is
our own. Pamphlets are written and distributed. Art and whispers are traded.
The forbidden is so seductive, is it not? Even here, where only things that
cause harm to others are called evil. The information-gleaners know that
what they do is wrong. They know this is what destroyed the old cities. And
indeed, they are horrified at what they hear through the speakers, see on the
screens. They begin to perceive that ours is a world where the notion
that some people are less important than others has been allowed to take
root, and grow until it buckles and cracks the foundations of our humanity.
“How could they?” the gleaners exclaim, of us. “Why would they do such
things? How can they just leave those people to starve? Why do they not
listen when that one complains of disrespect? What does it mean that these
ones have been assaulted and no one, no one, cares? Who treats other
people like that?” And yet, even amid their marvel, they share the idea. The
evil . . . spreads.
So the social workers of Um-Helat stand, talking now, over the body of a
man. He is dead—early, unwilling, with a beautifully crafted pike jammed
through his spine and heart. (The spine to make it painless. The heart to
make it quick.) This is only one of the weapons carried by the social workers,
and they prefer it because the pike is silent. Because there was no shot or
ricochet, no crackle or sizzle, no scream, no one else will come to
investigate. The disease has taken one poor victim, but it need not claim
more. In this manner is the contagion contained . . . in a moment. In a
moment.
Beside the man’s body crouches a little girl. She’s curly-haired, plump, blind,
brown, tall for her age. Normally a boisterous child, she weeps now over her
father’s death, and her tears run hot with the injustice of it all. She heard him
say, “I’m sorry.” She saw the social workers show the only mercy possible.
But she isn’t old enough to have been warned of the consequences of
breaking the law, or to understand that her father knew those consequences
and accepted them—so to her, what has happened has no purpose or
reason. It is a senseless, monstrous, and impossible thing, called murder.
“I’ll get back at you,” she says between sobs. “I’ll make you die the way you
made him die.” This is an unthinkable thing to say. Something is very wrong
here. She snarls, “How dare you. How dare you.”
The social workers exchange looks of concern. They are contaminated
themselves, of course; it’s permitted, and frankly unavoidable in their line of
work. Impossible to dam a flood without getting wet. (There are measures in
place. The studs on their scalps—well. In our own world, those who
volunteered to work in leper colonies were once venerated, and imprisoned
with them.) The social workers know, therefore, that for incomprehensible
reasons, this girl’s father has shared the poison knowledge of our world with
her. An uncontaminated citizen of Um-Helat would have asked “Why?” after
the initial shock and horror, because they would expect a reason. There
would be a reason. But this girl has already decided that the social workers
are less important than her father, and therefore the reason doesn’t matter.
She believes that the entire city is less important than one man’s selfishness.
Poor child. She is nearly septic with the taint of our world.
Nearly. But then our social worker, the tall brown one who got a hundred
strangers to smile at a handmade ladybug, crouches and offers a hand to the
child.
What? What surprises you? Did you think this would end with the cold-eyed
slaughter of a child? There are other options—and this is Um-Helat, friend,
where even a pitiful, diseased child matters. They will keep her in quarantine,
and reach out to her for several days. If the girl accepts the hand, listens to
them, they will try to explain why her father had to die. She’s early for the
knowledge, but something must be done, do you see? Then together they
will bury him, with their own hands if they must, in the beautiful garden that
they tend between caseloads. This garden holds all the Um-Helatians who
broke the law. Just because they have to die as deterrence doesn’t mean
they can’t be honored for the sacrifice.
But there is only one treatment for this toxin once it gets into the blood:
fighting it. Tooth and nail, spear and claw, up close and brutal; no quarter can
be given, no parole, no debate. The child must grow, and learn, and become
another social worker fighting an endless war against an idea . . . but she will
live, and help others, and find meaning in that. If she takes the woman’s
hand.
Does this work for you, at last, friend? Does the possibility of harsh
enforcement add enough realism? Are you better able to accept this
postcolonial utopia now that you see its bloody teeth? Ah, but they did not
choose this battle, the people of Um-Helat today; their ancestors did, when
they spun lies and ignored conscience in order to profit from others’ pain.
Their greed became a philosophy, a religion, a series of nations, all built on
blood. Um-Helat has chosen to be better. But sometimes, only by blood
sacrifice may true evil be kept at bay.
And now we come to you, my friend. My little soldier. See what I’ve done? So
insidious, these little thoughts, going both ways along the quantum path.
Now, perhaps, you will think of Um-Helat, and wish. Now you might finally be
able to envision a world where people have learned to love, as they learned
in our world to hate. Perhaps you will speak of Um-Helat to others, and
spread the notion farther still, like joyous birds migrating on trade winds. It’s
possible. Everyone—even the poor, even the lazy, even the undesirable—can
matter. Do you see how just the idea of this provokes utter rage in some?
That is the infection defending itself . . . because if enough of us believe a
thing is possible, then it becomes so.
And then? Who knows. War, maybe. The fire of fever and the purging
scourge. No one wants that, but is not the alternative to lie helpless, spotty
and blistered and heaving, until we all die?
So don’t walk away. The child needs you, too, don’t you see? You also have
to fight for her, now that you know she exists, or walking away is
meaningless. Here, here is my hand. Take it. Please.
Good. Good.
Now. Let’s get to work.




Page
1
of 4
The Ones Who Walk Away From Omelas
From The Wind's Twelve Quarters: Short Stories
by Ursula Le Guin
With a clamor of bells that set the swallows soaring, the Festival of Summer came to the
city Omelas, bright-towered by the sea. The rigging of the boats in harbor sparkled with flags. In
the streets between houses with red roofs and painted walls, between old moss-grown gardens
and under avenues of trees, past great parks and public buildings, processions moved. Some were
decorous: old people in long stiff robes of mauve and grey, grave master workmen, quiet, merry
women carrying their babies and chatting as they walked. In other streets the music beat faster, a
shimmering of gong and tambourine, and the people went dancing, the procession was a dance.
Children dodged in and out, their high calls rising like the swallows' crossing flights, over the
music and the singing. All the processions wound towards the north side of the city, where on the
great water-meadow called the Green' Fields boys and girls, naked in the bright air, with mud-
stained feet and ankles and long, lithe arms, exercised their restive horses before the race. The
horses wore no gear at all but a halter without bit. Their manes were braided with streamers of
silver, gold, and green. They flared their nostrils and pranced and boasted to one another; they
were vastly excited, the horse being the only animal who has adopted our ceremonies as his own.
Far off to the north and west the mountains stood up half encircling Omelas on her bay. The air
of morning was so clear that the snow still crowning the Eighteen Peaks burned with white-gold
fire across the miles of sunlit air, under the dark blue of the sky. There was just enough wind to
make the banners that marked the racecourse snap and flutter now and then. In the silence of the
broad green meadows one could hear the music winding through the city streets, farther and
nearer and ever approaching, a cheerful faint sweetness of the air that from time to time trembled
and gathered together and broke out into the great joyous clanging of the bells.
Joyous! How is one to tell about joy? How describe the citizens of Omelas?
They were not simple folk, you see, though they were happy. But we do not say the
words of cheer much any more. All smiles have become archaic. Given a description such as this
one tends to make certain assumptions. Given a description such as this one tends to look next
for the King, mounted on a splendid stallion and surrounded by his noble knights, or perhaps in a
golden litter borne by great-muscled slaves. But there was no king. They did not use swords, or
keep slaves. They were not barbarians. I do not know the rules and laws of their society, but I
suspect that they were singularly few. As they did without monarchy and slavery, so they also
got on without the stock exchange, the advertisement, the secret police, and the bomb. Yet I
repeat that these were not simple folk, not dulcet shepherds, noble savages, bland utopians. They
were not less complex than us. The trouble is that we have a bad habit, encouraged by pedants
and sophisticates, of considering happiness as something rather stupid. Only pain is intellectual,
only evil interesting. This is the treason of the artist: a refusal to admit the banality of evil and
the terrible boredom of pain. If you can't lick 'em, join 'em. If it hurts, repeat it. But to praise
despair is to condemn delight, to embrace violence is to lose hold of everything else. We have
almost lost hold; we can no longer describe a happy man, nor make any celebration of joy. How
can I tell you about the people of Omelas? They were not naive and happy children – though
their children were, in fact, happy. They were mature, intelligent, passionate adults whose lives
were not wretched. O miracle! but I wish I could describe it better. I wish I could convince you.
Omelas sounds in my words like a city in a fairy tale, long ago and far away, once upon a time.
Perhaps it would be best if you imagined it as your own fancy bids, assuming it will rise to the
occasion, for certainly I cannot suit you all. For instance, how about technology? I think that
there would be no cars or helicopters in and above the streets; this follows from the fact that the
people of Omelas are happy people. Happiness is based on a just discrimination of what is
necessary, what is neither necessary nor destructive, and what is destructive. In the middle
category, however – that of the unnecessary but undestructive, that of comfort, luxury,
exuberance, etc. -- they could perfectly well have central heating, subway trains,. washing
machines, and all kinds of marvelous devices not yet invented here, floating light-sources,
fuelless power, a cure for the common cold. Or they could have none of that: it doesn't matter.
As you like it. I incline to think that people from towns up and down the coast have been coming
in to Omelas during the last days before the Festival on very fast little trains and double-decked
trams, and that the train station of Omelas is actually the handsomest building in town, though
plainer than the magnificent Farmers' Market. But even granted trains, I fear that Omelas so far
strikes some of you as goody-goody. Smiles, bells, parades, horses, bleh. If so, please add an
orgy. If an orgy would help, don't hesitate. Let us not, however, have temples from which issue
beautiful nude priests and priestesses already half in ecstasy and ready to copulate with any man
or woman, lover or stranger who desires union with the deep godhead of the blood, although that
was my first idea. But really it would be better not to have any temples in Omelas – at least, not
manned temples. Religion yes, clergy no. Surely the beautiful nudes can just wander about,
offering themselves like divine souffles to the hunger of the needy and the rapture of the flesh.
Let them join the processions. Let tambourines be struck above the copulations, and the glory of
desire be proclaimed upon the gongs, and (a not unimportant point) let the offspring of these
delightful rituals be beloved and looked after by all. One thing I know there is none of in Omelas
is guilt. But what else should there be? I thought at first there were no drugs, but that is
puritanical. For those who like it, the faint insistent sweetness of drooz may perfume the ways of
the city, drooz which first brings a great lightness and brilliance to the mind and limbs, and then
after some hours a dreamy languor, and wonderful visions at last of the very arcana and inmost
secrets of the Universe, as well as exciting the pleasure of sex beyond all belief; and it is not
habit-forming. For more modest tastes I think there ought to be beer. What else, what else
belongs in the joyous city? The sense of victory, surely, the celebration of courage. But as we did
without clergy, let us do without soldiers. The joy built upon successful slaughter is not the right
kind of joy; it will not do; it is fearful and it is trivial. A boundless and generous contentment, a
magnanimous triumph felt not against some outer enemy but in communion with the finest and
fairest in the souls of all men everywhere and the splendor of the world's summer; this is what
swells the hearts of the people of Omelas, and the victory they celebrate is that of life. I really
don't think many of them need to take drooz.
Most of the processions have reached the Green Fields by now. A marvelous smell of
cooking goes forth from the red and blue tents of the provisioners. The faces of small children
are amiably sticky; in the benign grey beard of a man a couple of crumbs of rich pastry are
entangled. The youths and girls have mounted their horses and are beginning to group around the
starting line of the course. An old woman, small, fat, and laughing, is passing out flowers from a
basket, and tall young men, wear her flowers in their shining hair. A child of nine or ten sits at
the edge of the crowd, alone, playing on a wooden flute. People pause to listen, and they smile,
but they do not speak to him, for he never ceases playing and never sees them, his dark eyes
wholly rapt in the sweet, thin magic of the tune.
He finishes, and slowly lowers his hands holding the wooden flute.
As if that little private silence were the signal, all at once a trumpet sounds from the
pavilion near the starting line: imperious, melancholy, piercing. The horses rear on their slender
legs, and some of them neigh in answer. Sober-faced, the young riders stroke the horses' necks
and soothe them, whispering, "Quiet, quiet, there my beauty, my hope. . . ." They begin to form
in rank along the starting line. The crowds along the racecourse are like a field of grass and
flowers in the wind. The Festival of Summer has begun.
Do you believe? Do you accept the festival, the city, the joy? No? Then let me describe
one more thing.
In a basement under one of the beautiful public buildings of Omelas, or perhaps in the
cellar of one of its spacious private homes, there is a room. It has one locked door, and no
window. A little light seeps in dustily between cracks in the boards, secondhand from a
cobwebbed window somewhere across the cellar. In one corner of the little room a couple of
mops, with stiff, clotted, foul-smelling heads, stand near a rusty bucket. The floor is dirt, a little
damp to the touch, as cellar dirt usually is. The room is about three paces long and two wide: a
mere broom closet or disused tool room. In the room a child is sitting. It could be a boy or a girl.
It looks about six, but actually is nearly ten. It is feeble-minded. Perhaps it was born defective or
perhaps it has become imbecile through fear, malnutrition, and neglect. It picks its nose and
occasionally fumbles vaguely with its toes or genitals, as it sits haunched in the corner farthest
from the bucket and the two mops. It is afraid of the mops. It finds them horrible. It shuts its
eyes, but it knows the mops are still standing there; and the door is locked; and nobody will
come. The door is always locked; and nobody ever comes, except that sometimes-the child has
no understanding of time or interval – sometimes the door rattles terribly and opens, and a
person, or several people, are there. One of them may come and kick the child to make it stand
up. The others never come close, but peer in at it with frightened, disgusted eyes. The food bowl
and the water jug are hastily filled, the door is locked, the eyes disappear. The people at the door
never say anything, but the child, who has not always lived in the tool room, and can remember
sunlight and its mother's voice, sometimes speaks. "I will be good," it says. "Please let me out. I
will be good!" They never answer. The child used to scream for help at night, and cry a good
deal, but now it only makes a kind of whining, "eh-haa, eh-haa," and it speaks less and less often.
It is so thin there are no calves to its legs; its belly protrudes; it lives on a half-bowl of corn meal
and grease a day. It is naked. Its buttocks and thighs are a mass of festered sores, as it sits in its
own excrement continually.
They all know it is there, all the people of Omelas. Some of them have come to see it,
others are content merely to know it is there. They all know that it has to be there. Some of them
understand why, and some do not, but they all understand that their happiness, the beauty of their
city, the tenderness of their friendships, the health of their children, the wisdom of their scholars,
the skill of their makers, even the abundance of their harvest and the kindly weathers of their
skies, depend wholly on this child's abominable misery.
This is usually explained to children when they are between eight and twelve, whenever
they seem capable of understanding; and most of those who come to see the child are young
people, though often enough an adult comes, or comes back, to see the child. No matter how well
the matter has been explained to them, these young spectators are always shocked and sickened
at the sight. They feel disgust, which they had thought themselves superior to. They feel anger,
outrage, impotence, despite all the explanations. They would like to do something for the child.
But there is nothing they can do. If the child were brought up into the sunlight out of that vile
place, if it were cleaned and fed and comforted, that would be a good thing, indeed; but if it were
done, in that day and hour all the prosperity and beauty and delight of Omelas would wither and
be destroyed. Those are the terms. To exchange all the goodness and grace of every life in
Omelas for that single, small improvement: to throw away the happiness of thousands for the
chance of the happiness of one: that would be to let guilt within the walls indeed.
The terms are strict and absolute; there may not even be a kind word spoken to the child.
Often the young people go home in tears, or in a tearless rage, when they have seen the
child and faced this terrible paradox. They may brood over it for weeks or years. But as time
goes on they begin to realize that even if the child could be released, it would not get much good
of its freedom: a little vague pleasure of warmth and food, no doubt, but little more. It is too
degraded and imbecile to know any real joy. It has been afraid too long ever to be free of fear. Its
habits are too uncouth for it to respond to humane treatment. Indeed, after so long it would
probably be wretched without walls about it to protect it, and darkness for its eyes, and its own
excrement to sit in. Their tears at the bitter injustice dry when they begin to perceive the terrible
justice of reality, and to accept it. Yet it is their tears and anger, the trying of their generosity and
the acceptance of their helplessness, which are perhaps the true source of the splendor of their
lives. Theirs is no vapid, irresponsible happiness. They know that they, like the child, are not
free. They know compassion. It is the existence of the child, and their knowledge of its existence,
that makes possible the nobility of their architecture, the poignancy of their music, the profundity
of their science. It is because of the child that they are so gentle with children. They know that if
the wretched one were not there snivelling in the dark, the other one, the flute-player, could
make no joyful music as the young riders line up in their beauty for the race in the sunlight of the
first morning of summer.
Now do you believe in them? Are they not more credible? But there is one more thing to
tell, and this is quite incredible.
At times one of the adolescent girls or boys who go to see the child does not go home to
weep or rage, does not, in fact, go home at all. Sometimes also a man or woman much older falls
silent for a day or two, and then leaves home. These people go out into the street, and walk down
the street alone. They keep walking, and walk straight out of the city of Omelas, through the
beautiful gates. They keep walking across the farmlands of Omelas. Each one goes alone, youth
or girl man or woman. Night falls; the traveler must pass down village streets, between the
houses with yellow-lit windows, and on out into the darkness of the fields. Each alone, they go
west or north, towards the mountains. They go on. They leave Omelas, they walk ahead into the
darkness, and they do not come back. The place they go towards is a place even less imaginable
to most of us than the city of happiness. I cannot describe it at all. It is possible that it does not
exist. But they seem to know where they are going, the ones who walk away from Omelas.




Page
1
of 10
The Exploited Labor Behind Artificial
Intelligence
Supporting transnational worker organizing should be
at the center of the fight for “ethical AI.”
By Adrienne Williams, Milagros Miceli and Timnit Gebru October 13, 2022
Adrienne Williams and Milagros Miceli are
researchers at the Distributed AI Research (DAIR)
Institute. Timnit Gebru is the institute’s founder and
executive director. She was previously co-lead of
the Ethical AI research team at Google.
The public’s understanding of artificial intelligence (AI) is largely shaped by
pop culture — by blockbuster movies like “The Terminator” and their
doomsday scenarios of machines going rogue and destroying humanity. This
kind of AI narrative is also what grabs the attention of news outlets: a Google
engineer claiming that its chatbot was sentient was among the most
discussed AI-related news in recent months, even reaching Stephen
Colbert’s millions of viewers. But the idea of superintelligent machines with
their own agency and decision-making power is not only far from reality — it
distracts us from the real risks to human lives surrounding the development
and deployment of AI systems. While the public is distracted by the specter
of nonexistent sentient machines, an army of precarized workers stands
behind the supposed accomplishments of artificial intelligence systems
today.
Many of these systems are developed by multinational corporations located
in Silicon Valley, which have been consolidating power at a scale that,
journalist Gideon Lewis-Kraus notes, is likely unprecedented in human
history. They are striving to create autonomous systems that can one day
perform all of the tasks that people can do and more, without the required
salaries, benefits or other costs associated with employing humans. While
this corporate executives’ utopia is far from reality, the march to attempt its
realization has created a global underclass, performing what anthropologist
Mary L. Gray and computational social scientist Siddharth Suri call ghost
work: the downplayed human labor driving “AI”.
Tech companies that have branded themselves “AI first” depend on heavily
surveilled gig workers like data labelers, delivery drivers and content
moderators. Startups are even hiring people to impersonate AI systems like
chatbots, due to the pressure by venture capitalists to incorporate so-called
AI into their products. In fact, London-based venture capital firm MMC
Ventures surveyed 2,830 AI startups in the EU and found that 40% of them
didn’t use AI in a meaningful way.
Far from the sophisticated, sentient machines portrayed in media and pop
culture, so-called AI systems are fueled by millions of underpaid workers
around the world, performing repetitive tasks under precarious labor
conditions. And unlike the “AI researchers” paid six-figure salaries in Silicon
Valley corporations, these exploited workers are often recruited out of
impoverished populations and paid as little as $1.46/hour after tax. Yet
despite this, labor exploitation is not central to the discourse surrounding the
ethical development and deployment of AI systems. In this article, we give
examples of the labor exploitation driving so-called AI systems and argue
that supporting transnational worker organizing efforts should be a priority in
discussions pertaining to AI ethics.
We write this as people intimately connected to AI-related work. Adrienne is
a former Amazon delivery driver and organizer who has experienced the
harms of surveillance and unrealistic quotas established by automated
systems. Milagros is a researcher who has worked closely with data workers,
especially data annotators in Syria, Bulgaria and Argentina. And Timnit is a
researcher who has faced retaliation for uncovering and communicating the
harms of AI systems.
Treating Workers Like Machines
Much of what is currently described as AI is a system based on statistical
machine learning, and more specifically, deep learning via artificial neural
networks, a methodology that requires enormous amounts of data to “learn”
from. But around 15 years ago, before the proliferation of gig work, deep
learning systems were considered merely an academic curiosity, confined to
a few interested researchers.
In 2009, however, Jia Deng and his collaborators released the ImageNet
dataset, the largest labeled image dataset at the time, consisting of images
scraped from the internet and labeled through Amazon’s newly introduced
Mechanical Turk platform. Amazon Mechanical Turk, with the motto “artificial
artificial intelligence,” popularized the phenomenon of “crowd work”: large
volumes of time-consuming work broken down into smaller tasks that can
quickly be completed by millions of people around the world. With the
introduction of Mechanical Turk, intractable tasks were suddenly made
feasible; for example, hand-labeling one million images could be
automatically executed by a thousand anonymous people working in parallel,
each labeling only a thousand images. What’s more, it was at a price even a
university could afford: crowdworkers were paid per task completed, which
could amount to merely a few cents.
“So-called AI systems are fueled by millions of underpaid workers around
the world, performing repetitive tasks under precarious labor conditions.”
The ImageNet dataset was followed by the ImageNet Large Scale Visual
Recognition Challenge, where researchers used the dataset to train and test
models performing a variety of tasks like image recognition: annotating an
image with the type of object in the image, such as a tree or a cat. While
non-deep-learning-based models performed these tasks with the highest
accuracy at the time, in 2012, a deep-learning-based architecture informally
dubbed AlexNet scored higher than all other models by a wide margin. This
catapulted deep-learning-based models into the mainstream, and brought
us to today, where models requiring lots of data, labeled by low-wage gig
workers around the world, are proliferated by multinational corporations. In
addition to labeling data scraped from the internet, some jobs have gig
workers supply the data itself, requiring them to upload selfies, pictures of
friends and family or images of the objects around them.
Unlike in 2009, when the main crowdworking platform was Amazon’s
Mechanical Turk, there is currently an explosion of data labeling companies.
These companies are raising tens to hundreds of millions in venture capital
funding while the data labelers have been estimated to make an average of
$1.77 per task. Data labeling interfaces have evolved to treat crowdworkers
like machines, often prescribing them highly repetitive tasks, surveilling their
movements and punishing deviation through automated tools. Today, far
from an academic challenge, large corporations claiming to be “AI first” are
fueled by this army of underpaid gig workers, such as data laborers, content
moderators, warehouse workers and delivery drivers.
Content moderators, for example, are responsible for finding and flagging
content deemed inappropriate for a given platform. Not only are they
essential workers, without whom social media platforms would be
completely unusable, their work flagging different types of content is also
used to train automated systems aiming to flag texts and imagery containing
hate speech, fake news, violence or other types of content that violates
platforms’ policies. In spite of the crucial role that content moderators play in
both keeping online communities safe and training AI systems, they are often
paid miserable wages while working for tech giants and forced to perform
traumatic tasks while being closely surveilled.
Every murder, suicide, sexual assault or child abuse video that does not
make it onto a platform has been viewed and flagged by a content
moderator or an automated system trained by data most likely supplied by a
content moderator. Employees performing these tasks suffer from anxiety,
depression and post-traumatic stress disorder due to constant exposure to
this horrific content.
Besides experiencing a traumatic work environment with nonexistent or
insufficient mental health support, these workers are monitored and
punished if they deviate from their prescribed repetitive tasks. For instance,
Sama content moderators contracted by Meta in Kenya are monitored
through surveillance software to ensure that they make decisions about
violence in videos within 50 seconds, regardless of the length of the video or
how disturbing it is. Some content moderators fear that failure to do so could
result in termination after a few violations. “Through its prioritization of
speed and efficiency above all else,” Time Magazine reported, “this policy
might explain why videos containing hate speech and incitement to violence
have remained on Facebook’s platform in Ethiopia.”
Similar to social media platforms which would not function without content
moderators, e-commerce conglomerates like Amazon are run by armies of
warehouse workers and delivery drivers, among others. Like content
moderators, these workers both keep the platforms functional and supply
data for AI systems that Amazon may one day use to replace them: robots
that stock packages in warehouses and self-driving cars that deliver these
packages to customers. In the meantime, these workers must perform
repetitive tasks under the pressure of constant surveillance — tasks that, at
times, put their lives at risk and often result in serious musculoskeletal
injuries.
“Data labeling interfaces have evolved to treat crowdworkers like machines,
often prescribing them highly repetitive tasks, surveilling their movements
and punishing deviation through automated tools.”
Amazon warehouse employees are tracked via cameras and their inventory
scanners, and their performance is measured against the times managers
determine every task should take, based on aggregate data from everyone
working at the same facility. Time away from their assigned tasks is tracked
and used to discipline workers.
Like warehouse workers, Amazon delivery drivers are also monitored through
automated surveillance systems: an app called Mentor tallies scores based
on so-called violations. Amazon’s unrealistic delivery time expectations push
many drivers to take risky measures to ensure that they deliver the number
of packages assigned to them for the day. For instance, the time it takes
someone to fasten and unfasten their seatbelt some 90-300 times a day is
enough to put them behind schedule on their route. Adrienne and many of
her colleagues buckled their seat belts behind their backs, so that the
surveillance systems registered that they were driving with a belt on, without
getting slowed down by actually driving with a belt on.
In 2020, Amazon drivers in the U.S. were injured at a nearly 50% higher rate
than their United Parcel Service counterparts. In 2021, Amazon drivers were
injured at a rate of 18.3 per 100 drivers, up nearly 40% from the previous
year. These conditions aren’t only dangerous for delivery drivers —
pedestrians and car passengers have been killed and injured in accidents
involving Amazon delivery drivers. Some drivers in Japan recently quit in
protest because they say Amazon’s software sent them on “impossible
routes,” leading to “unreasonable demands and long hours.” In spite of these
clear harms, however, Amazon continues to treat its workers like machines.
In addition to tracking its workers through scanners and cameras, last year,
the company required delivery drivers in the U.S. to sign a “biometric
consent” form, granting Amazon permission to use AI-powered cameras to
monitor drivers’ movements — supposedly to cut down on distracted driving
or speeding and ensure seatbelt usage. It’s only reasonable for workers to
fear that facial recognition and other biometric data could be used to perfect
worker-surveillance tools or further train AI — which could one day replace
them. The vague wording in the consent forms leaves the precise purpose
open for interpretation, and workers have suspected unwanted uses of their
data before (though Amazon denied it).
The “AI” industry runs on the backs of these low-wage workers, who are kept
in precarious positions, making it hard, in the absence of unionization, to
push back on unethical practices or demand better working conditions for
fear of losing jobs they can’t afford to lose. Companies make sure to hire
people from poor and underserved communities, such as refugees,
incarcerated people and others with few job options, often hiring them
through third party firms as contractors rather than as full time employees.
While more employers should hire from vulnerable groups like these, it is
unacceptable to do it in a predatory manner, with no protections.
“AI ethics researchers should analyze harmful AI systems as both causes
and consequences of unjust labor conditions in the industry.”
Data labeling jobs are often performed far from the Silicon Valley
headquarters of “AI first” multinational corporations — from Venezuela,
where workers label data for the image recognition systems in self-driving
vehicles, to Bulgaria, where Syrian refugees fuel facial recognition systems
with selfies labeled according to race, gender, and age categories. These
tasks are often outsourced to precarious workers in countries like India,
Kenya, the Philippines or Mexico. Workers often do not speak English but are
provided instructions in English, and face termination or banning from
crowdwork platforms if they do not fully understand the rules.
These corporations know that increased worker power would slow down
their march toward proliferating “AI” systems requiring vast amounts of data,
deployed without adequately studying and mitigating their harms. Talk of
sentient machines only distracts us from holding them accountable for the
exploitative labor practices that power the “AI” industry.
An Urgent Priority For AI Ethics
While researchers in ethical AI, AI for social good, or human-centered AI
have mostly focused on “debiasing” data and fostering transparency and
model fairness, here we argue that stopping the exploitation of labor in the AI
industry should be at the heart of such initiatives. If corporations are not
allowed to exploit labor from Kenya to the U.S., for example, they will not be
able to proliferate harmful technologies as quickly — their market
calculations would simply dissuade them from doing so.
Thus, we advocate for funding of research and public initiatives that aim to
uncover issues at the intersection of labor and AI systems. AI ethics
researchers should analyze harmful AI systems as both causes and
consequences of unjust labor conditions in the industry. Researchers and
practitioners in AI should reflect on their use of crowdworkers to advance
their own careers, while the crowdworkers remain in precarious conditions.
Instead, the AI ethics community should work on initiatives that shift power
into the hands of workers. Examples include co-creating research agendas
with workers based on their needs, supporting cross-geographical labor
organizing efforts and ensuring that research findings are easily accessed by
workers rather than confined to academic publications. The Turkopticon
platform created by Lilly Irani and M. Six Silberman, “an activist system that
allows workers to publicize and evaluate their relationships with employers,”
is a great example of this.
Journalists, artists, and scientists can help by drawing clear the connection
between labor exploitation and harmful AI products in our everyday lives,
fostering solidarity with and support for gig workers and other vulnerable
worker populations. Journalists and commentators can show the general
public why they should care about the data annotator in Syria or the
hypersurveilled Amazon delivery driver in the U.S. Shame does work in
certain circumstances and, for corporations, the public’s sentiment of
“shame on you” can sometimes equal a loss in revenue and help move the
needle toward accountability.
Supporting transnational worker organizing should be at the center of the
fight for “ethical AI.” While each workplace and geographical context has its
own idiosyncrasies, knowing how workers in other locations circumvented
similar issues can serve as inspiration for local organizing and unionizing
efforts. For example, data labelers in Argentina could learn from the recent
unionizing efforts of content moderators in Kenya, or Amazon Mechanical
Turk workers organizing in the U.S., and vice versa. Furthermore, unionized
workers in one geographic location can advocate for their more precarious
counterparts in another, as in the case of the Alphabet Workers Union, which
includes both high paid employees in Silicon Valley and outsourced low
wage contractors in more rural areas.
“This type of solidarity between highly-paid tech workers and their lower-
paid counterparts — who vastly outnumber them — is a tech CEO’s
nightmare.”
This type of solidarity between highly-paid tech workers and their lower-paid
counterparts — who vastly outnumber them — is a tech CEO’s nightmare.
While corporations often treat their low-income workers as disposable,
they’re more hesitant to lose their high-income employees who can quickly
snap up jobs with competitors. Thus, the high-paid employees are allowed a
far longer leash when organizing, unionizing, and voicing their
disappointment with company culture and policies. They can use this
increased security to advocate with their lower-paid counterparts working at
warehouses, delivering packages or labeling data. As a result, corporations
seem to use every tool at their disposal to isolate these groups from each
other.
Emily Cunningham and Maren Costa created the type of cross-worker
solidarity that scares tech CEOs. Both women worked as user experience
designers at Amazon’s Seattle headquarters cumulatively for 21 years. Along
with other Amazon corporate workers, they co-founded the Amazon
Employees for Climate Justice (AECJ). In 2019, over 8,700 Amazon workers
publicly signed their names to an open letter addressed to Jeff Bezos and
the company’s board of directors demanding climate leadership and
concrete steps the company needed to implement to be aligned with climate
science and protect workers. Later that year, AECJ organized the first
walkout of corporate workers in Amazon’s history. The group says over
3,000 Amazon workers walked out across the world in solidarity with a
youth-led Global Climate Strike.
Amazon responded by announcing its Climate Pledge, a commitment to
achieve net-zero carbon by 2040 — 10 years ahead of the Paris Climate
Agreement. Cunningham and Costa say they were both disciplined and
threatened with termination after the climate strike — but it wasn’t until AECJ
organized actions to foster solidarity with low-wage workers that they were
actually fired. Hours after another AECJ member sent out a calendar invite
inviting corporate workers to listen to a panel of warehouse workers
discussing the dire working conditions they were facing at the beginning of
the pandemic, Amazon fired Costa and Cunningham. The National Labor
Relations Board found their firings were illegal, and the company later settled
with both women for undisclosed amounts. This case illustrates where
executives’ fears lie: the unflinching solidarity of high-income employees
who see low-income employees as their comrades.
In this light, we urge researchers and journalists to also center low-income
workers’ contributions in running the engine of “AI” and to stop misleading
the public with narratives of fully autonomous machines with human-like
agency. These machines are built by armies of underpaid laborers around
the world. With a clear understanding of the labor exploitation behind the
current proliferation of harmful AI systems, the public can advocate for
stronger labor protections and real consequences for entities who break
them.




Page
1
of 9
O R I G I N A L P A P E R
Towards a just and fair Internet: applying Rawls’ principles
of justice to Internet regulation
David M. Douglas
Published online: 21 January 2015
Ó The Author(s) 2015. This article is published with open access at Springerlink.com
Abstract I suggest that the social justice issues raised by
Internet regulation be exposed and examined by using a
methodology adapted from that described by John Rawls in
A Theory of Justice. Rawls’ theory uses the hypothetical
scenario of people deliberating about the justice of social
institutions from the ‘original position’ as a method of
removing bias in decision-making about justice. The ori-
ginal position imposes a ‘veil of ignorance’ that hides the
particular circumstances of individuals from them so that
they will not be influenced by self-interest. I adapt Rawls’
methodology by introducing an abstract description of
information technology to those deliberating about justice
from within the original position. This abstract description
focuses on information devices that users can use to access
information (and which may record information about
them as well) and information networks that information
devices use to communicate. The abstractness of this
description prevents the particular characteristics of the
Internet and the computing devices in use from influencing
the decisions about the just use and regulation of infor-
mation technology and networks. From this abstract posi-
tion, the principles of justice that the participants accept for
the rest of society will also apply to the computing devices
people use to communicate, and to Internet regulation.
Keywords Rawls  Distributive justice  Rights  Social
contract  Internet regulation
Introduction
The structure of the Internet is under greater scrutiny by
users and governments alike as various stakeholders
(including users, Internet service providers, corporations,
and states) attempt to increase their control over it. A few
recent examples illustrate the scale of these debates. Tim
Berners-Lee has recently promoted efforts for citizens of
individual countries to draw up a ‘Bill of Rights’ for Internet
users in their countries (Kiss 2014). Proposals that the
International Telecommunication Union (ITU) and the UN
should play a greater role in Internet governance have been
fiercely rejected by European and North American govern-
ments, among others, due to concerns about how this may
impact on the liberty of Internet users (Cerf 2013). Despite
this, the National Telecommunications and Information
Administration in the US (2014) has announced that it
intends to pass its control over the Internet domain name
system (DNS) to the international community. Finally and
most visibly, the assumptions made by individuals about the
security and privacy of Internet communications and ser-
vices have been challenged by recent disclosures about the
widespread interception and collection of global Internet
traffic by the National Security Agency (NSA) in the US
(Greenwald and MacAskill 2013).
These controversies and incidents show that we are far
from a consensus on Internet regulation. The early dreams
of an Internet free from regulation and control by tradi-
tional governments, powerfully expressed in writings such
as Barlow’s Declaration of the Independence of Cyber-
space (1996), are now long gone. What remains are urgent
questions about how the Internet should operate and how
best to regulate it so that it conforms to our expectations.
I claim that focusing on the characteristics of the
Internet obscures these questions by placing too great an
D. M. Douglas (&)
University of Twente, Enschede, The Netherlands
e-mail: d.m.douglas@utwente.nl
123
Ethics Inf Technol (2015) 17:57–64
DOI 10.1007/s10676-015-9361-1
emphasis on how the Internet currently operates rather than
considering how it should operate. For instance, calls for
Internet access to be a human right are often ambiguous
about what ‘Internet access’ means in this context. ‘Internet
access’ might be understood as the ability to connect a
computer to a network using Internet protocols, access to
the World Wide Web, or access to a full suite of Internet
applications such as email, web services, online gaming,
and so on. This ambiguity obscures the moral and political
concerns about the communication needs of individuals
and groups, and what restrictions on communicating
information (if any) states and network operators may
legitimately impose. Exploring what our notions of justice
require from information networks may highlight the hid-
den assumptions about users and communication that have
influenced the design and implementation of the Internet
and the tools that utilize it. It also helps to clarify what
exactly is necessary to satisfy a proposed human right to
access the Internet. 1
I suggest that the social contract tradition in political
philosophy offers a useful approach to exploring what a
fair and just Internet would look like. Social contract the-
ories use thought experiments of idealized situations where
individuals agree on the terms by which they will form a
society. This agreement is the ‘social contract’ that
describes a just society that has the consent of those who
belong to it. Social contract theories offer an idealized
conception of society that serves as a useful benchmark for
comparing existing societies and social institutions against
them.
For a social contract for the Internet, I will draw on the
social contract theory Rawls presents in A Theory of Justice
(1971). Rawls’ account is highly influential and has
inspired a vast literature exploring its claims and justifi-
cations. Rawls describes a methodology for arriving at an
unbiased agreement on the principles of justice that should
inform the institutions of society. His methodology uses
what he calls the ‘original position’ as its starting point,
where the individuals who must agree on the form society
should take have no knowledge about their individual cir-
cumstances in society. This ‘veil of ignorance’ prevents
individuals in the original position from making self-
interested decisions about society by denying them infor-
mation about who they will be within the society they
design. Rawls argues that for this reason, the individuals
are motivated to ensure that the position of the worst-off in
society will at least be tolerable as there is a chance that
each individual taking part in these discussions could be
one of the worst-off.
Applying social contract theory to issues in Internet
regulation is nothing new. Barlow’s Declaration of the
Independence of Cyberspace (1996) explicitly states that a
social contract between Internet users should be the means
by which the network is governed. Rawls’ theory itself has
also been used to evaluate issues of social justice in
information technology [for instance, Duff (2006, 2011)
and van den Hoven and Rooksby (2008)]. My approach
here contributes to the literature in two ways. Firstly, it
offers an abstract account of the Internet that removes most
of the details that may obscure or derail discussions of how
information networks should be regulated. Using abstract
conceptions of ‘computing devices’ and ‘information net-
works’ instead of ‘computers’ and ‘the Internet’ addresses
concerns about how specific details of how the Internet and
the systems using it may obscure our thinking about how
they should be used. Secondly, my approach offers an
alternative to basing claims for Internet regulation on
human rights. Claims that access to the Internet should be a
human right are often vulnerable to objections of ‘rights
inflation’, where additions to the broadly accepted set of
human rights risk undermining their value as absolutes. 2
My approach avoids these objections by allowing claims
about Internet regulation to be based on a social contract
that all would accept rather than on the human rights of
those involved.
The outline of this paper is as follows. I begin with a
brief description of Rawls’ theory and his method for
eliminating bias in decisions about justice. I then describe
how information technology can be introduced into the
deliberations made behind the veil of ignorance. This step
introduces the concept of ‘computing devices’ and ‘infor-
mation networks’ as aspects of society that need to be
considered in the social contract. The remainder of this
paper discusses the possible outcomes from using Rawls’
principles of justice to guide Internet regulation and con-
siders some objections to this approach.
Rawls’ theory of justice
Rawls’s theory contains a richness and depth that any brief
account of it cannot hope to adequately capture it. At best I
can hope to outline the aspects that are important for my
argument. In essence, Rawls’ theory is based on what he
calls ‘justice as fairness’: fair principles of justice will be
agreed to in fair circumstances where only the relevant
moral and practical reasons will influence the decision
(Rawls 1971). Rawls’ work presents both a methodology
for deciding on the principles of justice that should
underpin society and its’ institutions (the public rules
defining the actions, responsibilities, and expectations of
the various offices that exist within society) and a set of
1 I thank an anonymous reviewer for this point. 2 Cerf (2012) raises this objection, for example.
58 D. M. Douglas
123
principles of justice that he argues would be adopted after
using his methodology. Rawls’ methodology is important
for how it attempts to ensure fairness by removing bias and
self-interest from decision-making about justice.
Rawls’ methodology relies on the concept of a contract
made between rational beings to base his principles of
justice. Instead of looking back to an imaginary past to see
how society might have been formed (as Locke and
Rousseau did in their social contracts), Rawls uses what he
calls ‘the original position’ as a scenario for determining a
just arrangement of society. The original position is
intended to capture the perspective of the ‘noumenal self’,
the ‘‘free and equal rational being’’ who’s decisions are
unaffected by bias and circumstances (Rawls 1971,
pp. 255–256). This concept draws on Kant’s distinction
between the physical body (the phenomenal self) that is
affected by casual laws and the non-physical mind or
rational being (the noumenal self) that is not. Rawls’
methodology does not require this to be an actual distinc-
tion; only that it is possible for someone to adopt this
perspective for the purposes of the thought experiment.
Like the state of nature, the original position is a
hypothetical scenario where individuals devise the contract
by which they agree to form a society and to be bound by
its laws (Rawls 1971). The participants in the original
position act as representatives of those who will live in the
society that will follow the theories of justice and the
political institutions that emerge from their discussion. 3
The participants have no knowledge of who they might be
in that society: their individual circumstances and whatever
benefits or disadvantages they may have are unknown to
them. The participants are behind what Rawls (1971) calls
a ‘veil of ignorance’ (p. 12). Hiding this information makes
the participants’ decisions fair and impartial by removing
the sources of prejudice and self-interest that may affect
their judgment (Rawls 1971). This allows the participants
to better fulfill the unbiased perspective of the noumenal
self. Due to this uncertainty about who they might be
outside of the veil of ignorance, the participants will agree
on a theory of justice that offers the best circumstances for
the worst-off in that society, as they could be one of the
worst-off themselves. The combination of the original
position and the veil of ignorance serve to make the
interests of the worst-off the interests of everyone, as any
of the decision makers could belong to this group once the
veil is lifted and they enter into the society they have
developed.
To guide the participants in their decision-making,
Rawls (1971) introduces the concept of primary goods,
which he describes as things any rational person would
want, regardless of what her goals for her own life are. The
more primary goods someone has, the likelihood that she
can achieve her own life plan increases, and so a rational
person will prefer institutions where she has more primary
goods instead of less. Primary goods include rights, liber-
ties, powers, opportunities, wealth, income, and self-
respect. The participants in the original position each seek
to ensure that they will possess as many primary goods as
they can. The possibility that they themselves might be the
worst-off in society motivates the participants to ensure
that the principles of justice and the institutions of society
provide the worst-off with acceptable amounts of primary
goods.
As a result of the deliberations carried out in the original
position, the participants will have to choose between
different principles of justice that will serve as the foun-
dation for how the institutions of their society should be
arranged. Rawls (1971) argues that the participants in the
original position will settle on the following principles of
justice:
1. Each person is to have an equal right to the most
extensive total system of equal basic liberties compat-
ible with a similar system of liberty for all.
2. Social and economic inequalities are to be arranged so
that they are both:
(a) to the greatest benefit of the least advantaged,
consistent with the just savings principle, and
(b) attached to offices and positions open to all
under conditions of fair equality of opportunity
(p. 302).
These two principles can be called the Principle of
Equal Basic Liberties and the Difference Principle
respectively. 4 The basic liberties described in the first
principle include the rights to vote and be eligible to run for
public office, freedoms of speech and assembly, freedoms
of conscience and thought, freedom of the person, the right
to own private property, and freedom from arbitrary arrest
and the seizure of possessions (Rawls 1971). These prin-
ciples are then used to evaluate the institutions within that
society.
How might the Internet be represented within the
framework of primary goods and Rawls’ principles of
distributive justice? As Duff (2011) notes, several authors
have argued that information should be added to the list of
primary goods given by Rawls. For example, van den
Hoven and Rooksby (2008) propose access to information
as a primary good, which they define as ‘‘a level of access
3 For the purposes of this paper the representatives in the original
position can be thought of as specific individuals who will inhabit the
society created through the social contract they develop.
4 Whether adopting the methods of the original position and the veil
of ignorance will necessarily lead us to these principles of justice are
questions I will not address here.
Towards a just and fair Internet 59
123
to an informative object such that that access would be
sufficient to produce knowledge’’ (emphasis in original) (p.
381). Access to information allows individuals to gain the
knowledge necessary to devise and perform their own life
plan. van den Hoven and Rooksby (2008) also rightly argue
that access to information should be classified as a basic
liberty, and so should be distributed following the Principle
of Equal Basic Liberties. This also permits some limita-
tions on the information can access, if those limitations
permit everyone to enjoy the same liberties. For instance,
the liberty to hold property is limited by the restriction that
you cannot arbitrarily take what someone else owns away
from them, otherwise there is an unequal liberty in holding
property (since you can keep yours and she cannot keep
hers). Similarly, van den Hoven and Rooksby (2008) state
that an equal liberty to access information can be con-
strained by privacy protections for personal information
and restrictions on the use of intellectual property.
Opportunities to access information can be also dis-
tributed according to the Difference Principle (van den
Hoven and Rooksby 2008). In this context, this means that
inequalities in access to the Internet are permissible only if
they to the benefit of the worst-off in society. Combining
this with the Principle of Equal Basic Liberties, this pro-
poses that everyone should have an equal liberty to access
the Internet, while permitting inequalities in how it is
accessed provided that everyone benefits from permitting
these inequalities.
The four-stage sequence
Rawls recognizes that a gap exists between formulating
general principles of justice and the laws and regulations that
implement them in society, and offers a four-stage sequence
to overcome this gap. This sequence gradually introduces
further information to those behind the veil of ignorance, until
finally all information is revealed and the participants dis-
cover their actual circumstances within society.
Rawls (1971) distinguishes between three kinds of facts:
social theory from first principles (which are all that is
available in the original position), general information
about a particular society, and specific information about
individuals. The second and third kinds of facts are grad-
ually revealed as the four-stage sequence progresses.
The four-stage sequence consists of:
1. The original position. Only general social theory is
made available to the participants, allowing them to act
as their ‘noumenal selves’ by removing potential
sources of bias in their decisions (Rawls 1971,
p. 255). This stage was explained in the previous
section.
2. General information about the society is now revealed
to the participants. This stage serves as a constitutional
convention where the participants act as delegates to
decide on a just political constitution that reflects the
principles of justice agreed upon in the first stage.
3. This is the legislative stage where laws are proposed
that implement the decisions made in the constitutional
stage. The participants here act as legislators who
evaluate laws and policies in light of the principles of
justice accepted in the first stage and the constitution
accepted in the second. Rawls (1971) states that the
representatives can move between the constitutional
and legislative stages to resolve problems that emerge.
4. The judicial stage makes all relevant information
available to the participants. The participants act as
judges and administrators who apply the laws and
policies accepted in stage 3, and as the citizens who
abide by them (Rawls 1971).
A brief example should help to illustrate how this pro-
cess works. As discussed in the previous section, the par-
ticipants in the original position decide on a set of
principles that will judge the society will create. For the
sake of the argument, I will assume that they select Rawls’
two principles of justice. Now that this is decided, the
discussion moves to the second stage, the ‘constitutional
convention’. While the participants are still unaware of
who they might be within society, they are now informed
of their society, such as the natural resources available to it
and the level of economic development (Rawls 1971). With
this information, they can begin to formulate how the
requirements of justice already decided upon can be
implemented given the resources available to their society.
As a result, they devise a constitution for their society that
will serve as the benchmark for the legislative and judicial
stages that follow.
The legislative and judicial stages are similar to how
laws are written and revised in constitutional govern-
ments. 5 The constitution serves as the basis for the laws
and judicial decisions in society. If serious issues emerge
between the principles of justice and the laws that follow
the constitution emerge, the constitution itself may be
amended to better reflect what the principles of justice
require.
5 An idealized view of the relationship between the constitution of
the United States, the laws of the US Government, and the decisions
of the US Supreme Court is a helpful analogy to keep in mind here.
The government can impose laws which the Supreme Court may find
unconstitutional if they are challenged, and amendments to the
constitution are possible if there is political agreement on the need to
do so.
60 D. M. Douglas
123
Introducing information technology into the four-stage
sequence
I propose that an abstract description of information tech-
nology should be introduced in stage 2, with more specific
information about it introduced in stages 3 and 4 as nec-
essary. First the significant features of information tech-
nology need to be defined. This description needs to be
general enough so it does not presuppose arbitrary features,
but not so general that it does not allow us to make useful
decisions about how it should governed and regulated. The
primary good of access to information that van den Hoven
and Rooksby (2008) present is an excellent starting point to
which abstract concepts of the Internet and how we access
it can be added.
The phrase ‘information technology’ itself provides a
starting point: it involves artefacts that deal with storing,
transmitting, and presenting information to those who uti-
lize them. Such artefacts might store information by
recording it in a form from which it can be retrieved later,
transmit it by conveying it to another artefact that might
store, transmit, or present it, or present information in a
way intelligible to the user of the artefact. Not every
artefact covered by the term information technology will
have all of these attributes: a telephone line transmits
information, but does not by itself store or present it (these
functions would be fulfilled by sound recorders and tele-
phones, in this case).
What makes computers different from the information
technologies that preceded them is their capacity to act
upon instructions given to them (i.e., their capacity to be
programmed and to perform computation). Computers can
control the information they store, transmit, and present
according to the instructions contained in their program-
ming. This creates the possibility of such devices per-
forming actions without the user’s knowledge. If even the
scale and complexity of the software running on modern
computing devices is ignored, suggesting that users have
complete knowledge of what the computing devices they
possess are doing and how it will respond to transmitted
instructions from other devices via a network places a
heavy burden on the user. It is more realistic to claim that
the device may act in ways in which the user is unaware.
This claim can be phrased as the possibility that a com-
puting device may store and transmit information that she
is aware of. 6
The transmission of information requires a medium
through which the computing devices can communicate.
This medium is represented as an information network: a
series of connections between devices that allows for
information to pass between them. The information
accessible to a computing device is significantly limited if
it does not have access to such a network. At best, such a
device can access and present information that the user can
physically input into it via physical storage media (such as
portable hard drives, compact discs, flopping disks, cas-
settes, and so on). Connecting to an information network
expands the range of information accessible to any given
device significantly. It also creates greater opportunities for
others to gain access to the information on a user’s device.
Someone can only access the information stored on an
unconnected device if she has physical access to it,
increasing the likelihood that the user knows that the data
stored on it has been accessed (and by whom). The
accessibility of the information stored on a connected
device will depend on the programming of the device and
whether there are any safeguards that prevent information
from being shared with any other computing device that
attempts to access it. This possibility increases the risk of
the user’s privacy being invaded.
The complexity of the software running on modern
computers and the scale of computer networks are just two
examples of how information technology is a social prod-
uct: it is not the work of isolated individuals but the result
of the social organization and co-operation necessary to
create and maintain it. This brings information technology
into the realm of distributive justice as something that the
distribution of can be controlled by society. The usage and
distribution of information technology should reflect the
same notions of justice that guide the rest of society.
An objection here is that information networks do not
necessarily have to be social products and thus subject to
the requirements of distributive justice. Anarchistic net-
works made up of uncoordinated individuals are an alter-
native possibility. Wireless mesh networks are a means of
forming and maintain an unplanned network along these
lines, for example (Akyildiz et al. 2005). This objection is
correct in noting the possibility that public information
networks are not an inevitable outcome of having net-
workable computing devices. I see two responses to this
objection. Firstly, the technology and resources necessary
to create private networks will be result of developing
public network infrastructure, as suggested by the history
of the Internet’s development. This is a contestable claim,
especially given how many uses of the Internet have
emerged through private developers, and it is vulnerable to
the response that an equivalent to the Internet could have
emerged through private, uncoordinated means. The sec-
ond, and perhaps more convincing response, is to suggest
that the principles of distributive justice discussed here
would be useful if the private individuals who create such a
6 It could not, by definition, present information that the user is
unaware of. Presentation necessarily involves making someone aware
of whatever is being presented. Whether it is understood is another
matter.
Towards a just and fair Internet 61
123
network themselves decide to make it accessible to others.
These principles maintain their value as a guide for
deciding how formerly private resources that are granted to
society at large can be fairly accessed and distributed. 7
From these general points about information technology
we can along with the other information supplied in stage
2, the participants are given the following description of
information technology:
1. Each individual may possess one or more computa-
tional devices that she uses to access and store
information. (These are computing devices).
2. The information stored on these devices may be
transmitted to other computing devices via a network.
(Such networks are information networks).
3. The actions described in points 1 and 2 may occur with
or without the knowledge of the possessor of the
computing device.
4. Computing devices and information networks are
products of social co-operation.
This definition contains the points that computing
devices store and present information, and information can
be transmitted between them via a network. It also states
that users may be unaware of the information that their
devices are storing and transmitting. The breadth of this
description captures the significant aspects of these devices
without confining it to the particular features of specific
devices that are in use. This prevents the particular char-
acteristics of specific devices and networks from influ-
encing the decisions of those behind the veil of ignorance.
It is irrelevant at this stage whether these devices are
desktop PCs, laptops, tablets, or smartphones. While these
devices differ significantly in their capabilities, the issues
of justice concerning the use of the information they
access, store and transfer remain the same at this point.
An immediate objection is that this description of
information technology is abstract to the point of vacu-
ousness. This objection claims that by refusing to define
these devices in anything but the vaguest of terms, my
account loses what is important about information tech-
nology from the perspective of social justice. My response
is that this vagueness is necessary to avoid implicit bias in
the decisions made about how we should use information
technology. Historical accidents and arbitrary choices
dominate information technology: the choice of ‘big-en-
dian’ or ‘little-endian’ byte ordering (Tanenbaum 2006),
the ubiquity of the concepts originating in the Unix oper-
ating system (Lanier 2010), even the QWERTY keyboard
layout, to name just a few. The insights from disclosive
ethics about how implicit biases affect the design of arti-
facts also suggest that we should be cautious in identifying
particular aspects of information devices as necessary and
non-arbitrary (Introna 2011). As the deliberations at this
stage are intended to serve as the basis for a constitution,
there should be as few assumptions made about the char-
acteristics of information technology as possible. More
specific information about the form these devices and
networks take can be introduced in stages 3 and 4 where
such details are necessary for drafting legislation and
implementing law.
My reasoning for including information devices and
networks in stage 2 rather than in stage 1 (the initial ori-
ginal position) is modesty about the role of information
technology in society. The changes information technology
makes to society are notoriously difficult to predict, as a
casual glance over the historical literature on how com-
puters will affect society will confirm. This will be
unconvincing to anyone who considers information tech-
nology to be a radically disruptive force in society. If this is
the case, information about devices and communication
networks will have to be included in stage 1 of the delib-
erations, joining the other fundamental facts about society
that Rawls considers necessary for meaningful yet unbiased
decisions.
I do not wish to claim that this is not the only such
description of information technology that could be pre-
sented to participants at the second stage of Rawls’ four-
stage sequence. I do suggest, however, that any such a
description must share the broad characteristics of the
account I have developed here: that ‘information devices’
are capable of recording, storing, and transmitting infor-
mation across a network, such devices are the result of
social cooperation and are not necessarily possessed by
every individual within society, and that such devices are
capable of performing these actions both with and without
the knowledge of whoever possesses them.
From information networks to the Internet
How do these concepts of information devices and net-
works translate into policy on the Internet? As the delib-
erations move to stages 3 and 4 of the sequence, we can
begin to distinguish between different kinds of information
devices and networks and consider whether different forms
of regulation are appropriate for them.
With Rawls’ principles of justice in mind we can reach
some general conclusions about what justice requires from
information technology. Computing devices and informa-
tion networks should encourage the acquisition of primary
goods, or at least should not undermine the user’s posses-
sion of such goods. The access to information networks
that information devices expand the possibilities for each
individual’s access of information and her ability to7 I thank an anonymous reviewer for raising this objection.
62 D. M. Douglas
123
produce knowledge. The information stored by these
devices and conveyed across these networks should be in
accord with the rights individuals possess, and should
follow the Principle of Equal Basic Liberties. As these
devices are capable of revealing information about their
user to others, the participants will want to have control
over what information these devices may reveal about
them. As access to information is a primary good, indi-
viduals will want their devices to be open to receiving
information. Such information will also assist them in
pursuing their own life plan. Information networks should
similarly promote access to information. The rules gov-
erning the information exchanged by their devices will also
conform to the social institutions that they have devised for
the rest of society. From this position, the institutions that
govern the exchange of information between computing
devices should be just.
From this we can derive a definition for what a just
information network requires:
A just network allows for accessing and exchanging
information in ways that support the primary goods of
those who use it and are in accordance with the
principles of justice.
And similarly, for the devices used to access an informa-
tion network:
Computing devices must allow users to control
information in ways that are consistent with their own
conception of the good and are in accordance with the
principles of justice.
The vagueness of these definitions is appropriate for stage
2 (the constitutional stage) of the deliberations, as they can
be refined into specific legislation and policies in the
following stages. Like the principles of justice, they serve
as guidelines for drafting and revising the more specific
policies that will emerge when more information is
revealed to the participants in this decision-making
process.
The participants would also seek to address the prob-
lems raised by the additional uncertainty over whether they
will possess an information device in society. (Recall that
point 1 of the abstract description of information technol-
ogy states that ‘‘Each individual may possess one or more
devices’’). This forces the participants to address the
inequalities raised by the ‘digital divide’ between those
who have access to information technology and those who
do not. These concerns are addressed by the requirements
that access and use of information devices and networks
must follow the principles of justice. If possessing infor-
mation devices and access to information networks are
desirable, the worst-off in society will now be the worst-off
group in society envisioned in stage 1 (the original
position) who additionally do not possess information
devices. The participants will therefore be motivated to
ensure that the disadvantages of belonging to this group
will not be intolerable.
The constitutional stage (stage 2) appears to reflect what
the World Wide Web Foundation (n.d.) is promoting with
its’ ‘Web We Want’ campaign, where individuals are
encouraged to come together to discuss how the Internet
should be regulated. I suggest that adopting a methodology
similar to the one I have described would be a useful tool
for assisting these deliberations, especially as a method of
reassuring non-participating stakeholders that self-interest
is not motivating the participants’ decisions.
There is a major objection to using Rawls’ methodology
that I must address: that Rawls’ scope for social justice
does not include international justice, which would be
necessary for addressing concerns about Internet regula-
tion. Rawls confines this methodology to determining jus-
tice within a society, rather than between different
societies. It operates only on a national rather than an
international level. Rawls (1985) himself states that his
theory of justice for institutions is applicable only to
‘‘modern constitutional democracies’’ (p. 224). This is a
significant problem for using this method to examine
questions of justice about the Internet given the interna-
tional issues it raises.
Rawls’ methodology can be adapted to address this
problem, and many authors have used Rawls’ framework
as a starting point for developing theories of international
justice (Blake and Smith 2013). 8 For issues about inter-
national Internet regulation, the participants would be
representatives of the populations of individual countries
but without any knowledge of which country they are
representing. They will be given information about the
general circumstances and social norms of individual
countries, as well the relative inequalities in wealth and
influence of different countries. The worst-off group would
then be the people of the most-disadvantaged country.
There remains the problem of governments that disagree
with the liberal assumptions that underpin Rawls’ theory
and his conception of primary goods and basic liberties.
While making the participants representatives of the pop-
ulations instead of the governments of different countries
may offer a partial solution where government policies do
not reflect the wishes of their people (i.e., governments that
rely on the use or threat of force to remain in power), it
does little to resolve this problem if the population shares
their illiberal views. The concept of ‘overlapping consen-
sus’ that Rawls (2005) develops in his later work Political
8 Rawls (1999) himself describes a different approach to international
justice in The Law of Peoples. I will not discuss it further here due to
limited space and scope.
Towards a just and fair Internet 63
123
Liberalism offers a possible response to this problem.
Overlapping consensus seeks acceptance of the institutions
themselves and how they operate from a variety of per-
spectives (Rawls 2005). While the controversies concern-
ing Internet regulation suggest that such consensus will be
difficult to reach, nonetheless it offers a method for
countries and groups with diverse political and social
commitments to find common ground despite their
differences.
Conclusion
In this paper I outlined how Rawls’ theory of justice can be
applied to questions about the just regulation of informa-
tion networks. I argued that the abstract conception of
information technology described here used in conjunction
with Rawls’ theory removes concerns about how the
practical details of technology obscures our thinking about
how networks such as the Internet should operate. Using an
abstract approach such as the one presented here helps us to
use what we have learned from the history of the Internet
and the development of information and communication
technology to inform our thinking about how they should
operate rather than confining it.
Acknowledgments I would like to thank the delegates of the 2013
Australasian Association of Philosophy Conference who inspired this
paper by their helpful and insightful comments on an earlier paper
where I discussed whether Internet access should be a human right. I
also thank the anonymous reviewers of Ethics and Information
Technology for their helpful suggestions and criticisms.
Open Access This article is distributed under the terms of the
Creative Commons Attribution License which permits any use, dis-
tribution, and reproduction in any medium, provided the original
author(s) and the source are credited.




Page
1
of 24
This is an author-produced, post-review, pre-copyedit typescript of a chapter to appear in The Moral Psychology
of Trust,
eds. David Collins, Iris Vidmar Jovanović
, and Mark Alfano (Lexington Books, 2023). Please cite the
version of record.
OK, Google, Can I Trust You?
An Anti-Trust Argument for Antitrust
Trystan S. Goetze, Harvard University
tgoetze@fas.harvard.edu
Abstract
In this paper, I argue that it is impossible to trust the Big Tech companies, in an ethically
important sense of trust. The argument is not that these companies are untrustworthy. Rather, I
argue that the power to hold the trustee accountable is a necessary component of this sense of
trust, and, because these companies are so powerful, they are immune to our attempts, as
individuals or nation-states, to hold them to account. It is, therefore, literally impossible to trust Big
Tech. After introducing the accounts of trust and power that I deploy, I argue that Big Tech
companies have four kinds of power that render them unaccountable: fiscal power, political power,
data power, and cognitive power. I conclude by reflecting on recent calls to break up the Big Tech
firms, suggesting a new antitrust test in the light of my arguments.
1. Introduction: Trust and the Techlash
This leaves us with the question that I think we are still dealing with today: “What do you do
when the most powerful institutions in society have become the least accountable to society?”
And I think that’s the question that our generation exists to answer.
—Edward Snowden, speaking via video call to the Web Summit conference (2019).
Public confidence in technology firms has fallen precipitously since 2015, in the wake of data
breaches, political scandals, biased AI systems, and suggestions that social media is a driving force
in the rise of online misinformation anti-democratic authoritarianism.1
In the media, this shift in
1
In 2010, Pew Research found that U.S. Americans placed the tech sector with small businesses, religious
organizations, and colleges and universities, as the only institutions of which they had a net positive impression
(Rosentiel 2010). From 2015 to 2019, however, the proportion of respondents who had a favourable view of the tech
sector fell from 71 per cent to 50 per cent; this drop was consistent across the Democratic–Republican partisan divide
(Auxier, Anderson, and Kumar 2019).
2
public opinion has widely been called the
techlash. In response, technology firms have stepped up
their efforts to enact ethical best practices – or at least, to give the
appearance of having enacted
them (Floridi 2019) – in order to regain public trust. This is much as we might expect: in business
as in personal relationships, the received wisdom is that when trust is violated, the once-trusted
party must take steps not just to make amends to those whose trust was directly violated, but also to
assure all who have trusted them, or who may need to trust them in the future, that they are worthy
of being trusted again. And it is surely to the good if technology firms aspire to be worthy of our
trust and take steps in this direction.
However, when it comes to the largest players at the centre of the techlash – namely, the
Big
Tech firms – it is possible that there is
nothing they could do to earn our trust.2
But this is not
because their actions and inactions have been so egregious that they are forever untrust
worthy.
Rather, I will argue that these firms are untrust
able. The main thrust of my argument is that,
because of their power, there is no way for consumers, or even their political representatives, to
hold these firms accountable. But, it is a central requirement for trust that the truster have the
power to hold the trustee to account for violations of trust. Thus, no matter how the Big Tech
firms may change for the better in response to the techlash,
we literally cannot trust them as long as
they are worth calling “big” tech.
Here is the plan. In §2, I outline a theory of trust, and explain why, on this view, it is a
necessary condition of trust for the truster to be capable of holding the trustee accountable for
violations of trust. In §3, I outline an account of power, and argue that the ability to hold a
wrongdoer accountable is a form of power. In §4, I make the case that the power of Big Tech
firms makes it impossible for us to hold them accountable, thereby rendering them untrustable. In
§5, I address two objections. The first is that this view of trust and its relationship to power mean
that children cannot trust their parents. The second is a worry that more needs to be said about
group agency in order for group accountability or trust in groups to make sense. In §6, I conclude
by reflecting on the implications of my argument for calls to break up the Big Tech firms.
2
For the purposes of this paper, I take ‘Big Tech’ to refer to the so-called ‘Big Five’ – Alphabet (the holding company
that owns Google, FitBit, DeepMind, and Waymo, among others), Apple, Amazon, Meta (the holding company that
owns Facebook, Instagram, WhatsApp, and Oculus, among others), and Microsoft. However, there is good reason to
expand this list to include Alibaba, IBM, Tencent, and Baidu (Webb 2019).
3
2. Trust
In moral philosophy, it has become customary to distinguish between
trust and mere
reliance.
While we may trust
or rely upon people, organizations, or states, we can
only rely on things,
animals, and autonomous systems. For example, I can rely on my word processing software to
work without crashing unexpectedly, but I may trust the software developers to have designed a
stable application. I can rely on a geyser to erupt at a regular interval, but I may trust the tour guide
who assures me and my fiancée that Ol’ Faithful will go off when we visit for a wedding
photoshoot. I can rely on a bee colony to pollinate my crops, but I may trust the beekeeper whom
I hired to bring the bees to my farm.
Both trust and reliance involve some element of expectation – one trusts or relies upon
another to do something – and some element of vulnerability – if the agent one trusts or relies
upon fails to do as one expects, one will be worse off. The nuances of the trust/reliance distinction
are subject to much debate.3
For instance, Annette Baier argues that trust involves an expectation
that the trustee will act with goodwill towards the truster (Baier 1986). By contrast, Russell Hardin
argues that the trustee must act out of an interest in maintaining the trusting relationship, which
involves “encapsulating” the truster’s interests within their own (Hardin 2002). For the purposes of
this paper, I will deploy the theory developed by Margaret Urban Walker (2006) – she, in turn,
draws on Richard Holton’s work (Holton 1994).4
I use Walker’s view over the alternatives for several reasons. First, as we shall see shortly,
her account draws attention to the role of moral accountability in trust, which highlights features
that are important to my critique of the Big Tech companies. Second, because she does not base
trust in an assumption that the trustee has a particular motive or mental state (viz., goodwill or
encapsulated interests), it allows us to sidestep some questions about the moral psychology of
group agents, such as large corporations. Third, Walker develops her account of trust as a
component of her broader theory of
moral repair, the process whereby we restore relationships
after betrayals of trust and other forms of moral wrongdoing. As such, a critique of Big Tech from
this angle can be seen as a step towards moral repair between Big Tech and the rest of society.
Fourth, Walker’s view covers both the case of trusting someone
simpliciter, and trusting someone
3
For a more thorough summary of the literature, see McCleod (2021).
4
These views focus on
moral trust, but there are important differences when we think about
epistemic trust. I am
concerned only with the former in this paper.
4
to do something specific, whereas other views usually require a three-place relation: in Baier’s
terms, “A trusts B with valued thing C” (Baier 1986, 236). The broader scope of Walker’s account
is useful for my purposes, because, in my view, it isn’t entirely clear
what we might take ourselves
to trust Big Tech to do (to provide their services? not to misinform us? not to misuse our data?),
though it is clear that we now rely on them in many ways.
On Walker’s view, to
rely on someone or something is merely to expect that they or it will
behave in a particular way, and to plan one’s own life in anticipation of that outcome. Reliance is a
purely descriptive concept; nothing about one’s reliance on something implies that it
should
behave in the expected way, in any sense of “should.”
Trust, on the other hand, adds a normative
dimension to reliance, which can only be satisfied by a responsible agent:
[T]rust links reliance to responsibility. In trusting one has
normative expectations of others,
expectations of others that they will do what they should and hence that we are entitled to
hold them to it, if only in the form of rebuking and demanding feelings. (Walker, 2006, p.
80, italics hers)
In other words, when we trust someone, our expectations are not just about how they are
likely to
behave; rather, we expect that they will
act as they should. And since this expectation is grounded
in normative demands, we are entitled to hold the trustee accountable for failing to do as they
ought.
The scope of these normative expectations depends on the context and on the relationship
between the truster and the trustee. The truster may have general normative expectations that the
trustee will act ethically, such as the implicit trust that we show our fellows that they will not attack
us in the street. Or the truster may have expectations that the trustee will act as they should given
their social role, such as the trust we have towards journalists that they will not mislead us or exploit
the power that their social role gives them. Or the truster may expect that the trustee will act in
accordance with the norms of a specific interpersonal relationship that obtains between truster and
trustee, such as the expectation of faithfulness in romantic partnerships. Or the truster may have an
expectation that the trustee will perform a specific task at a specific moment without exploiting or
misleading the truster, such as the trust one shows to a stranger on the station platform when one
asks something like, “Pardon me; is this the Chattanooga Choo-Choo?”
5
Why add the further detail about accountability?5
Walker defends this move by turning to
Peter Strawson’s much-discussed essay on moral responsibility (Strawson 1962), where he defends
a distinction between two different stances we may take when responding to the harmful acts of
another. When we take the
participant attitude towards someone, we treat them as a fellow
member of the moral community, someone who is a responsible agent, responsive to moral
reasons and capable of goodwill towards others. When someone to whom we take the participant
attitude causes harm or otherwise transgresses a moral norm, we may respond to their wrongdoing
with communicative and punitive responses, such as feelings of resentment, the purpose of which
is to make them appreciate the moral reasons that they have ignored or flouted, feel bad for the
harms that their actions have caused, and take steps to make amends – as well as, potentially, our
own private catharsis. The software developer, tour guide, and beekeeper are agents toward whom
one might take the participant attitude – people we might blame if they fail to act as they should
given the normative expectations we have of them. For Walker, accountability is crucial to her
theory of moral repair. For, one component of making amends to one another after betrayals of
trust is to respond to being held accountable for the betrayal by demonstrating one’s remorse and
commitment to doing better in the future.
By contrast, those to whom we take the
objective attitude are treated instead as non-
responsible entities who must be trained, incentivized, corrected, managed, restricted, avoided, or
even terminated in order to protect ourselves from their harmful behaviour. We do not engage
with them as responsible agents who are responsive to moral reasons, opting instead for strategies
of behaviour modification that truncate or bypass any rational faculties that they may or may not
have. In cases where changing the entity’s behaviour is not possible, all we can do is regret what
happened or be disappointed that something didn’t happen, and move on. As Strawson notes, we
sometimes must take the objective attitude towards other human beings, when attempting to reason
with them would be futile or simply not worth the effort. On the other hand, the word processor,
geyser, and bee colony are the sorts of things to which we might take the objective attitude, but
not
the participant attitude. We might be disappointed if they fail to act as we are relying on them to
5
In this paper, I understand the notion of
accountability to encompass the activities we also refer to as
holding
someone responsible for wrongdoing. Holding someone accountable includes blaming, resenting, punishing, and
other methods of attempting to make the wrongdoer recognize that they acted wrongfully and to do better in the
future. See Shoemaker (2011) for discussion of this sense of “accountability” and how it is distinct from other senses of
responsibility in the literature.
6
do, but it would make little sense to
blame them. Therein lies the difference between things on
which we can only rely, and people whom we can trust: to be trustable, one must be a fellow
member of the moral community, the sort of entity that one could, in principle, hold accountable
for betraying one’s trust. Hence, reliance
plus responsibility constitutes trust.
3. Power
The next piece of conceptual machinery I want to add to this account of trust is the notion of
social
power. The relative power of wrongdoer and wronged often goes missing in theorizing on moral
responsibility, but it has profound effects on how we hold one another to account, and whether
such efforts are safe and effective.6
The account of power that I deploy here is that presented by Miranda Fricker as a prelude to
her discussion of epistemic injustice.7
On her view, social power is
a practically socially situated capacity to control others’ actions, where this capacity may be
exercised (actively or passively) by particular social agents, or alternatively, it may operate
purely structurally. (Fricker, 2007, p. 13, italics removed)
Let’s unpack this definition. By
practically socially situated, Fricker means that power requires a
functioning social world with shared institutions, meanings, expectations, and so on, because any
particular operation of social power requires the coordination of various individuals. In addition,
the notion of social situation, which stems from feminist accounts of how differences in social
identity are relevant epistemologically and otherwise, highlights that aspects of one’s social identity,
such as one’s gender or race, directly affect the amount of power that one has in various contexts.
Fricker also notes that power comes in two main types.
Agential power, on the one hand, is a
capacity that an individual agent can use to control the actions of others. It can be exercised actively
or passively, meaning that those who have it can intentionally choose to use their power to exert
control over others, or they may simply allow the shared understanding that they
have such power
to influence others’ behaviour without taking direct action themselves. An example of agential
power is a traffic cop’s capacity to issue tickets for illegal parking. The cop can exercise this power
actively, modifying people’s behaviour by issuing tickets, or they can allow the shared
6
Baier (1986) includes a discussion of power in her account of trust, which I will return to in §5 when discussing an
objection that Walker’s account suggests that children cannot trust their parents.
7
Fricker, in turn, is drawing on Michel Foucault (1980, 1982, 2003) and Thomas Wartenberg (1992).
7
understanding that people may be ticketed for parking violations to do the work, without actively
issuing any tickets.
Structural power, on the other hand, operates without the need for a particular agent who
has
power to exercise. One way structural power operates is by establishing, in our shared conceptions
of the social world, that people with certain characteristics or identities tend to think or behave in
certain ways, which then produces that behaviour in actuality.8
For example, a stereotype that men
are better at mathematics than women may contribute to the under-representation of women in
technical fields such as computer science. Another form of structural power is when opportunities
available to some groups are not available to others. For example, educational inequality arising
from inequitable distributions of government resources may mean some people have access to
different educational opportunities. Alongside this, an image of some groups rather than others
being “the sort of people" who seek and take up particular educational opportunities (e.g.
university vs. trade school) may shape people’s decisions about which forms of education to pursue
even if others are available to them.
Finally, while she acknowledges that theorists tend to invoke conceptions of power only when
it is causing harm to someone or some group, Fricker notes that her account is agnostic as to
whether particular operations of power are good, bad, or neutral in their effects. For example, in
some neighbourhoods, such as those in a downtown core, it may be beneficial to residents if the
traffic cop is aggressive in their exercise of the power to issue tickets for parking violations. But in
others, such as a residential neighbourhood, aggressive ticketing may be a form of harassment.
Fricker notes elsewhere that the act of blaming – one of our principal ways of holding
people morally accountable – can be thought of as “a moral species of social power” (Fricker,
2016, pp. 181–2).9
On her view, in blaming the wrongdoer (or holding them responsible by other
means), the blamer is engaged in an attempt to change the wrongdoer’s behaviour. Namely, the
blamer aims to spur the wrongdoer to recognize that they have done wrong, to acknowledge the
moral reasons they ignored or flouted, to correct their moral understandings and/or future
8
Cf. Ian Hacking’s concept of the
looping effect of human kinds (Hacking 1995), or Foucault’s notion of
subjectification.
9
It is perhaps worth noting that not all forms of blame are exercises of social power. Private feelings of blame, because
they are internal to the subject, are not exercises of power, for example. However, private blame is not a way of
holding the blamee accountable.
8
behaviour, and perhaps to engage in moral reparative work. In context, Fricker’s observation is
intended to flag that the power of blame can be used for good – e.g. holding wrongdoers to
account – or for ill – e.g. browbeating those with whom one disagrees into conformity. Hence, in
this passage Fricker raises the concern that a blamer might have
too much power over the blamee,
or that the blamer may abuse that power.
But we can just as easily invert this connection between power and blame:
there are some
instances where the blamer has too little
power relative to the wrongdoer. In these cases, the victim
of wrongdoing lacks the capacity to influence the behaviour of the wrongdoer by holding them
responsible for their actions. This situation can result from any of the forms of power presented
above. The wrongdoer may be in a social position where they can actively use their agential power
to silence or undercut their victim’s attempts to hold them responsible. For example, in response
to being accused of wrongdoing, the wrongdoer could take legal action to silence the victim, or
terminate the victim’s employment. Or the mere fact that the wrongdoer is in a position to take
such actions may passively operate to silence the victim before any attempt to hold the wrongdoer
accountable is made.
Structural power can also block the victim from holding the wrongdoer responsible. For
example, the victim may be a member of a group that is socialized to be non-confrontational and
submissive, discouraging them from speaking out about their mistreatment. Or, social institutions
may fail to provide any practical mechanism by which the victim can hold the wrongdoer to
account, for example, by pricing out people in the victim’s socio-economic class from exercising
their right to legal action, or by forcing the victim to use formal channels that are designed to
frustrate attempts to bring about meaningful change, or by sustaining patterns of credibility deficit
that result in testimonial injustices when the victim attempts to explain how they were wronged.
Even if all of these different machinations do not deter the victim from confronting the wrongdoer
with their blame, the wrongdoer’s power may place them in a position from which they may safely
dismiss or ignore the blamer’s attempts to hold them to account without consequence, thereby
undermining the very act of blaming.
For example, consider the well-known difficulties that accompany sexual harassment and
sexual assault allegations made by students against professors. In such a situation, the student is at a
disadvantage in their ability to hold their abuser to account because of their relative lack of social
power. They may find the power that the professor holds in the university institution to be a
9
deterrent to reporting the incident in the first place. They may find that confronting their abuser
leads to retaliation by way of lost opportunities or academic penalties. They may find it difficult for
their allegations to be taken seriously by the relevant authorities. Their allegations might be
dismissed as the words of a student against those of a colleague. If their allegations are taken
seriously, they still might not be handled with care, or bureaucratic and legal processes may fail to
deliver a meaningful response to the incident. Even if some resolution is reached, in many
instances it will not have a lasting impact on the offender’s career, undercutting the effectiveness of
holding them to account. In each of these variations, the relatively powerful wrongdoer is able to
escape some or all of the effects that we would expect to follow from the victim’s attempt to hold
them responsible, either by active or passive exercise of their social power, or by the operation of
structural power. A powerful wrongdoer can overrule the power of the blamer to hold them
responsible.
4. Big Tech
Let’s put these pieces together now, and apply them to Big Tech.
When one is incapable of holding a person responsible, this precludes one’s ability to trust
them. This is because, as we saw, trust is reliance plus responsibility. On the account of trust that I
presented, we can only trust entities of which we can have normative expectations. Built into this
notion is that we must be able to take the participant attitude – to treat the trustee as a member of
the moral community – which implies that we have the power to hold the trustee accountable
when they transgress moral norms. An entity that one cannot hold morally accountable is, thus, not
an entity toward whom one can take the participant attitude. And so,
if one lacks the power to hold
someone or something accountable for their actions, that person or entity is not something that
one can trust.
As suggested by Snowden in my epigraph, there are few institutions in modern life more
powerful than the Big Tech companies.10
First, they are among the wealthiest institutions in the
world, granting them significant agential power. That is to say, because they are wealthy, they have
the resources to actively exercise control over others in a variety of ways, and this capacity also
10
In context, Snowden’s remarks are about not just Big Tech but also Big Government (Web Summit 2019). By the
latter, I mean law enforcement, intelligence, and military organizations, and the governmental and judicial bodies that
have consistently supported these institutions in expanding state and corporate surveillance.
10
operates passively to discourage those who may be harmed by their actions from pursuing
remedies. For example, Alphabet’s annual revenue in 2019 was about US $162 billion (Wallach
2020), more than the 2020 GDP of Ukraine and over one hundred other sovereign nations
(World Bank 2020). The sheer fiscal power of these firms, then, puts them quite out of reach of
attempts by ordinary citizens, and even a good number of nations, to hold them accountable for
their wrongdoing. While internal dispute mechanisms offered by these firms are available in some
instances, their enforcement is notoriously capricious and changes frequently and without notice.
While lawsuits are an option, it is safe to say that very few people possess the means to launch a
legal case against a multinational with the resources of a medium-sized country. And this is not to
mention that the terms of use for the services provided by Big Tech – binding contracts that we all
agree to without reading – often explicitly require disputes to be resolved via arbitration, rather
than civil suits. Furthermore, in the United States, case law has often favoured technology
corporations. For example, since the 1996 decision in
Zeran v. America Online, Inc., companies
controlling online communications platforms, such as social media, cannot be sued in the USA for
harmful content posted by their users (Sheridan 1997). Taking these factors together, practically
speaking, very few of us can hold Big Tech accountable.
What about our elected representatives? One reason to have a government, after all, is that it
can pool resources and enforce regulations intended to protect us from powerful bad actors. But in
part because of their tremendous economic footprint, Big Tech firms also command a great deal
of
political power, not just in back-room lobbying, but also in tactics that increasingly resemble
nation-to-nation tit-for-tat in diplomatic disputes. Indeed, writing in
The Atlantic, Adrienne
LaFrance describes Facebook as a “hostile foreign power” and “the largest autocracy on Earth,”
which is “engaged in a cold war with the United States and other democracies” (LaFrance 2021).
For example, in early 2021, the Australian parliament introduced draft legislation that would
require Big Tech companies to share their advertising revenue with news companies whose links
are shared on social media and social news platforms. In response, Facebook blocked all news
from being displayed to Australian users, and Google threatened to disable its Search tool for
Australians – both in the middle of the biggest public health emergency in the last century (BBC
News 2021). Google backed down from their threat after global backlash; Facebook ended their
information blockade only after concessions from legislators were made (Cellan-Jones, 2021). This
was undoubtedly a flexing of power intended to test just how far these companies can go to resist
11
efforts to regulate them. And, since the Australian legislation was intended in part to rectify a harm
caused by companies such as Facebook and Google – namely, the decline of traditional
journalism, and with it, journalistic standards in online media – their resistance to this regulation
can be seen as resistance to being held accountable. Not every nation and not every government
can stand firm against such resistance – and, as mentioned, Australia was forced to compromise.
This form of power undermines even the efforts of powerful democratic governments to hold Big
Tech to account.
A third kind of power possessed by Big Tech is tied to their control over our
data. In
exchange for the free services offered by these companies, we allow them to collect, process, and
sell data on many facets of our lives. These data are collected not just from our interactions with
Big Tech services, but from our online and technologically enabled activities generally. Carissa
Véliz argues that in giving up our data so freely, we are abdicating a distinctive kind of power. As
Francis Bacon once wrote, knowledge is power, an adage Véliz reads in a pragmatist spirit: the
more you know about someone or something, the more effectively you can plan your actions when
they concern the subject of that knowledge. Véliz connects this observation to the idea that by
collecting data on a person, one is collecting knowledge about them, and that with knowledge
comes power: “Through protecting our privacy, we prevent others from being empowered with
knowledge about us that can be used against our interests” (Véliz 2020).
In other words, because Big Tech companies understand so much about us from our data –
in many cases, better than we understand ourselves – they can tap into this knowledge to predict
our thoughts and actions in response to various situations. As Simson Garfinkel wrote in 2000
(when Google was still just a search engine and the most popular social media platforms were
LiveJournal and classmates.com),
next-generation agents will scan the world for personal information about an individual, then
construct a predictive model for use by marketers and others...The profile could know every
document you’ve ever read, every person you’ve ever known, every place you’ve ever been,
and every word you’ve ever said that has been recorded. Your identity would no longer exist
just inside of you, but in the model. (Garfinkel 2000, 252)
Garfinkel refers to this process as the
extraction of the self: a model of one’s self is captured in a
computational system and used to predict how one will behave. The level of data power that the
Big Tech firms have today makes extracting the self possible. This is both a kind of agential power
12
that enables Big Tech to “nudge” our behaviour subtly in ways that may benefit them – including
pushing us away from attempts to hold them to account – and a kind of structural power that
makes life without their services difficult or nigh-inconceivable.11
Indeed, if we were to try to hold Big Tech accountable by denying them access to our data,
they would still have ways to coerce our compliance. While many of these firms put on airs of
giving us data control, our power to take control of our data can actually be quite limited.
Facebook and Google, for example, prompt the user on occasion to perform a “privacy check-up”
to confirm their data protection settings. But while these controls allow
some data collection and
processing to be switched off, there is no option to eliminate it entirely or even to reduce it to
strictly necessary purposes. In fact, these firms perform some data collection and aggregation on
you even if you do not have an account registered with them, thanks to trackers connected to their
advertising services across the web. We would not fare much better were we to attempt to boycott
their services instead. It has become difficult to opt out in this way because Big Tech services
underpin much of the structure of the modern internet. For example, Amazon Web Services
controlled a third of the market for cloud computing in 2020, and hosts a significant number of
other companies’ online services, including Netflix and Slack (Runkevicius 2020). Attempts at
digital boycott are likely to be incredibly difficult and ineffectual, as reporter Kashmir Hill
discovered when she struggled through an attempt to live without interacting with any of the Big
Five for a week while carrying on a normal life as a digital citizen – in her words, “it was hell” (Hill
2019).
The fourth kind of power possessed by Big Tech is what we may call
cognitive power. This is
the power not just to influence our behaviour, but to shape our very thoughts and values, which, it
goes almost without saying, are some of the most important sources of human behaviour. As James
Williams argues, the Big Tech companies have cognitive power in virtue of how they command
our
attention (Williams 2018). Using a series of illuminating metaphors, Williams outlines three
levels of attention that can be hijacked by the platforms controlled by Big Tech. First, there is what
he calls the
spotlight, our capacities to focus our immediate attention on a particular task or object.
Second, there is the
starlight, our broader capacities to direct our actions so that they will align with
our values. Third, there is the
daylight, our capacities that enable us to have and to reflectively
11
On nudging and the subtle power of design to influence behaviour, see Thaler and Sunstein (2008).
13
revise our beliefs and values in the first place. Our spotlight can be misdirected by technological
intrusions and nudges, such as notifications and alerts that pull our attention away from what we
mean to be doing and back to our social media news feeds. We can be pulled off-course from our
guiding starlight by coming to internalize the reward mechanisms that exist within the platforms
controlled by Big Tech. For example, Williams reports feeling compelled to act in ways that would
maximize the number of “likes,” “favourites,” “follows,” “friends,” “connections,” “shares,”
“reblogs”, and so on, on various platforms. He attributes a growing attitude of pettiness within
himself to this internalization of social media rewards as valuable objects to pursue, and goes on to
connect this sort of pettiness to political polarization, increases in the incidence of narcissism, and
deadly risk-taking behaviour by social media personalities. Finally, the daylight by which we discern
what is true and good can be occluded by the online spread of misinformation and moral outrage,
which are rewarded by algorithmic content feeds that prioritize a thin, behaviouristic metric of
“engagement” over thicker, more meaningful measures of quality.12
Cognitive power is especially dangerous to our ability to hold Big Tech accountable. By
leveraging this form of power, these companies can keep us distracted from their wrongdoing
(misdirecting our spotlight). They can encourage us to act as if the things that their platforms value
are what
we value, keeping us under their spell (pointing us away from our starlight). And they can
confuse us as to what is really true or false, and who is really good or bad, by virtue of the content
their platforms serve up (eclipsing our daylight). Each of these forms of cognitive power can
undercut our ability to hold Big Tech companies accountable by preventing us from doing so in
the first place – or by preventing us from even seeing the need.
Taken together, the fiscal power, political power, data power, and cognitive power possessed
by Big Tech firms renders them out of reach of attempts to hold them accountable. This goes not
just for individuals, but also for many – potentially all – nation-states. But, it is a requirement of
trust that the truster have the power to hold the trustee accountable for violating normative
expectations. Therefore, it is impossible for us to trust the Big Tech companies. Furthermore, the
fact that Big Tech can neither be trusted nor held accountable suggests something even more
disturbing:
these companies may not be members of the moral community. Since their power
insulates them from the giving, asking for, and responsiveness to moral reasons; expectations of
12
Cf. Nguyen’s discussion of how social media, and Twitter in particular, gamify communication (Nguyen 2021).
14
goodwill; and responsiveness to being held responsible that are part and parcel of participation in
the moral community, taking the participant attitude towards them no longer makes sense. Big
Tech companies are more akin to autocrats – or dangerous beasts – and should be treated as such.
5. Objections
Before we come to what we might do to counter the situation we find ourselves in, in this section, I
address two objections to my arguments. The first concerns the potential consequences of the view
of trust and accountability that I have presented, namely, that this view implies that children cannot
trust their parents. The second concerns the nature of Big Tech firms as group agents: it is possible
that accountability simply works differently when dealing with groups rather than persons.
5.1. Think of the Children!
A potentially troubling consequence of the account of trust that I have presented is that children
might not be able to trust their parents or guardians.13
After all, compared to adults, children have
much less social power, which may well mean that they lack the power to hold adults to account.
Indeed, it is an important aspect of childrearing that parents retain a significant degree of power
over their children; when exercised with care, parental power helps ensure the safety, healthy
development, and moral education of children. But at the same time, we also think that it is
important for children to be able to trust their parents; in fact, this trust might be taken to underpin
the permissibility of parental power as minors gradually become autonomous agents. Yet, on the
account I have presented, a child’s ability to trust their parents may seem at odds with their relative
lack of power. If children are relatively powerless compared to their parents, this might well
preclude their ability to hold their parents accountable for wrongdoing, which would, according to
the arguments I gave above, preclude children from being able to trust their parents.14
One way to respond to this objection would be to simply bite the bullet. Perhaps children
cannot trust their parents after all. It may be that children can only rely upon their parents. This
13
For brevity, I will refer only to parents from here on, but it should be understood that the conception of
parent that I
have in mind is broad, including different- and same-gender, biological, surrogate, adoptive, foster, and polyamorous
parents, as well as legally assigned guardians, grandparents or godparents assuming a primary parental role, other
adults in an extended family, and so on. Who counts as a parent in one family or another is dependent on their role in
that family, not biological relation.
14
Thanks to Carolyn McLeod, Letitia Meynell, Sue Sherwin, and others, for independently pushing me to respond to
this objection.
15
conclusion, while reshaping some of the contours of how we understand trust in our social
relations, does not strike me as especially strange. Given that children are, in many other ways,
developing their capacities as moral agents, their participation in the moral community is already
truncated. Why should their ability to trust be any different?
Another potential response to this objection is to note that in fact children
do sometimes
have the power to hold their parents accountable – though they may not always understand what
they’re doing. For example, my mom is fond of telling an anecdote about my childhood, wherein I
was upset at some demand or restriction of hers, and, in a fit of tiny rage, I exclaimed, “You’re a
bad mummy!” Now, she knew full well that this was not true – the source of contention, though I
don’t remember it now, was a perfectly reasonable request – yet this reproach still hurt her feelings
and made her question herself for a moment. If a child can succeed in rebuking their mother out
of misplaced frustration, surely they can do so when their parents have genuinely done something
wrong.
Or, it may be that a different, but still ethically significant, sense of trust obtains in the case of
children and parents. Baier describes “trust between infant and parent” as a “primitive and basic
trust” (1986, 245). By this, she means that children trust their parents by default. In fact, childrenmust uncritically trust their caregivers, both as a matter of biological survival and because they
initially lack the moral reasoning capacities needed to trust in the more robust sense outlined by
Walker. If this primitive form of trust is distinct from the sense I have employed, however, it is
plainly not the sort of trust we should have in Big Tech: it would be an affront to human dignity for
us to be reduced to a child-like state of helpless, uncritical vulnerability
vis-à-vis these corporations.
A final line of response to this objection is possible by noting that the problem of children’s
ability to trust their parents is just one form of a more general problem. Namely, when someone or
some group of people is vulnerable and relatively powerless compared to someone else, how can
we ensure that trust is still possible? This problem occurs with regard to the relationship between
citizens and the state, between students and teachers, between patients and medical professionals,
between civilians and the police, between account holders and banks, and generally whenever the
vulnerability of the truster is heightened by the greater power of the trustee. In each of these cases,
we set up formal structures to ensure accountability, and so secure the possibility of trust. Citizens
can oust their leaders in elections. Teachers and medical professionals are beholden to the policies
of their professional associations, and violating their codes of conduct leads to a bar on practising
16
in their field. The police have internal and external oversight. Banks are subject to various
consumer protection regulations. And in all of these cases, laws and practices have been
established to give vulnerable people the ability to hold those who abuse their power to account in
courts and tribunals. These systems are far from perfect, but when they work, their existence is an
essential part of what makes it possible for us to trust powerful people and institutions.
The same is true for children. Most democratic countries have strict child protection laws, as
well as legal duties for those acting in a parental role. Child neglect and abuse are serious crimes.
Special government agencies exist to protect children whose vulnerability has been exploited or
ignored by parents. Other adults have legal obligations to report suspected wrongdoing by parents.
And underpinning these legal mechanisms is a prior moral commitment common to all folk
moralities that the vulnerability of children means that they are owed special protection and care,
which adults are morally obligated to provide. Even if children are not often the ones who launch
such legal and ethical accountability procedures, the fact that these systems exist enables children
to maintain an attitude of trust towards their parents. Though they might not be able to hold their
own parents accountable themselves, others can do it for them.
The corollary, of course, is that when such institutions of accountability are systemic failures,
vulnerable people cannot trust the powerful after all. We have seen this most starkly with the
police in recent years, as their established impunity in unprovoked killings of people of colour is
subject to repeated challenge and outcry, to little avail. So far as the theory of trust goes, we should
welcome this result, as it provides a compelling and urgent reason to ensure that these formal
systems of accountability function properly. It explains, in part, why the police cannot be trusted,
why many who grow up in foster care do not trust the social services responsible for that system,
why many marginalized people are leery to trust medical professionals, and so on. Moreover, if my
arguments above are right, our situation with regard to Big Tech is substantively similar to that of
the child whose society has failed to provide working formal accountability processes. Our
regulatory frameworks are largely toothless when it comes to Big Tech, and that is part of the
problem.15
15
My account might also imply that we cannot trust all-powerful entities, such as God. What I would suggest in
response is that we can make a distinction between trust and faith. This might then show that while we cannot trust the
powerful when they are unaccountable to us, we can still have faith in them. Thanks to several audience members at
presentations I gave of this paper for raising this concern.
17
5.2. Group Accountability
Another worry might be that I have assumed too much in using an account of trust that was
designed for trust
between human persons to analyze a case of trust
between human persons and
large businesses – that is to say, between individuals and collectives. If groups can be held
accountable, we might think that it must be in a way different from Strawson’s conception of the
participant attitude. One might contend that because a collective, as such, has no mental states, it
cannot feel shame and cannot be subject to the power of moral blame to reshape its moral
understandings. Or, if collectives
can be subject to the power of moral blame, at the very least we
are owed some account of group agency that explains how.16
While a full defence of an account of
group agency and the responsibility of collectives is beyond the scope of this essay, I do have a few
potential responses to this objection.
One approach would be to adopt an account of group knowledge on which we can ascribe
moral understandings to a collective. The epistemology of collectives is largely focused on how to
explain the fact that collectives have knowledge, rather than establishing that group knowledge is
possible.17
And, if a group can have knowledge or beliefs, then,
a fortiori, a group can have moral
knowledge or beliefs. It stands to reason, then, that a collective could be influenced to change its
moral beliefs in response to reproach or other forms of pressure.
However, even if one rejects the possibility that a collective, such as a corporation, could
have moral beliefs or understanding, the possibility remains that a collective could be influenced by
the efforts of individuals or other collectives. There are several accounts of group agency that pay
particular attention to how we can hold corporations and similar collectives to account.18
Adjudicating between these positions on group beliefs and group accountability is not important
here; what matters is that a cogent account could, in principle, explain how corporate agents can be
held morally accountable.
Finally, regardless of how one conceives of collectives, the fact remains that they are at least
partially constituted by individual agents. And even if the collective has no psychology to influence,
its members do. By holding individual members of the collective to account, especially those in
16
Thanks to Ian Brooks for suggesting this objection.
17
See, among others, Bird (2014), Gilbert (1989; 1987; 2004), Tuomela (1992), Wray (2001).
18
See, among others, Cooper (1968), Feinberg (1968), French (1984), May (1992; 1987), Mellena (1997), Pettit (2007).
18
positions of power within the collective’s formal decision-making procedures, the collective itself
can be held responsible for its actions.19
Any remaining skeptics with regard to group accountability will have to contend with the fact
that concerted efforts to influence morally salient corporate behaviour have sometimes worked.
For example, from the 1930s to 1980s, a class of chemicals called chlorofluorocarbons (CFCs),
which include Freeon, were commonly used as refrigerants and aerosol propellants. In the late
1970s, scientists discovered that CFCs were destroying the Earth’s ozone layer, which shields
terrestrial life from dangerous ultraviolet solar radiation. By 1989, an international coalition of
governments had successfully passed regulations to phase out and ban CFCs in favour of non-
destructive chemicals. This top-down measure likely would not have succeeded without bottom-up
pressure from ordinary citizens and activist groups, who were quite reasonably outraged that
corporations were putting life on this planet at risk in pursuit of profit. And had it not succeeded, a
NASA Earth Observatory model predicts that by 2020, the concentration of the ozone layer over
North America would have declined by about half, and would have nearly completely been
depleted by 2060 (Carlowicz, Lindsey, and Simmon 2009). Regardless of whether one thinks that
manufacturing corporations had a change of
moral belief regarding the permissibility of using
CFCs in their products, the power exercised by concerned individuals, groups, and states
succeeded in changing these corporations’ behaviour for the better. And this is one of the goals of
exercising the power of moral blame. So I see no reason not to think that blame can, in some
situations, effect positive change in corporate behaviour.
The case of Big Tech, however, is disanalogous to that of CFC-using manufacturers. Big
Tech is, well, bigger, in the ways I have described earlier. Their power is greater and further-
reaching than that of companies who marketed aerosols and refrigerants in the 1970s. Attempts to
regulate Big Tech thus run up against more difficult barriers than environmental protection
legislation in the late twentieth century – which, of course, is not to say that such regulations were
easy to pass in the first place. If my arguments in this paper are right, then even if there is a
possibility that corporations’ moral beliefs or morally salient actions can be controlled by
accountability mechanisms, Big Tech firms remain an exception: their power renders them
unaccountable, untrustable, and dangerous.
19
Thanks to Duncan MacIntosh and Jeff Behrends for suggesting this point.
19
6. Conclusion: Break Them Up
In this paper, I have argued that the Big Tech companies cannot be trusted. The issue is not that
they are untrust
worthy, but rather, that they are untrust
able. The reason is that, on the view of trust
that I presented, trust requires that the truster have the power to hold the trustee accountable when
the trustee fails to act as they ought. And since the Big Tech companies possess a tremendous
amount of power – fiscal, political, data, and cognitive – they are able to resist and undercut
attempts by individuals and states to hold them to account. Thus, they quite literally cannot be
trusted. In light of this conclusion, I want to briefly suggest some next steps.
When an entity causes harm, but is not one to whom we take the participant attitude,
Strawson tells us that we may resort to cruder means of correcting its behaviour or protecting
ourselves from it. We may even be permitted to do so with someone who is otherwise a
responsible agent, should they fail to respond to our reasonable attempts to hold them
accountable. By retreating to the objective attitude, new lines of action open up – potentially
including
violence. And one way to strike back violently against a corporation is to break up its
holdings.20
In the nineteenth century, society was faced with a similar concentration of power in the
hands of a small number of companies. The oil barons – among them John D. Rockefeller, the
owner of Standard Oil and one of the richest men in world history – controlled so much wealth
and influence that the Canadian and U.S. governments were impelled to enact some of the earliest
modern antitrust legislation. The breakup of the Standard Oil monopoly followed in 1911, and
laid out the conditions for forcing the break-up of a large corporation or trust: break up the entity
when it can raise prices without losing customers.
Today, it is common to compare the Big Tech companies to the oil barons with the slogan
‘Data is the new oil’ (Economist 2017). As Catherine D’Ignazio and Lauren Klein observe,
It’s a metaphor that resonates uncannily well... The idea of data as some sort of untapped
natural resource clearly points to the potential of data for power and profit once they are
processed and refined, but it also helps to highlight the exploitative dimensions of extracting
data from their source – people – as well as their ecological cost... (D’Ignazio and Klein
2020)
20
An alternative could be to somehow
legitimate the power held by Big Tech. For some suggestions on this, see
Greene and Gilbert (ms.).
20
But the old antitrust test fails with the corporate powers that control the new oil. Because many of
their services are
free – or rather, offered to us
gratis in exchange for our data – there are no prices
for them to raise. A new antitrust test might emphasize a company’s ability to escape accountability
for its actions:
the more easily a company can evade accountability, the stronger the case for
breaking it up. The point of such a test is not to protect the
market, but to protect the
people. By
breaking up the Big Tech companies, we may reduce their power by reducing their financial assets,
their political influence, their data assets, and their avenues for misdirecting our attention. In so
doing, we may restore these companies’ status as participants in the moral community, instead of
as dangerous forces outside it.
Acknowledgements
I presented earlier forms of this paper several times in 2021: at Congress of the Canadian
Philosophical Association, to the Dalhousie University philosophy graduate students’ writing
group, as a job talk at the University of King’s College, to the Talk Shop at Harvard University, and
to the Philosophy Colloquium at Dalhousie University. For feedback on earlier versions of this
material, I’d like to specifically thank Carolyn McCleod, Jacquie Burkell, Char Harrison, Clarisse
Schuetz, Lara Millman, Erik Nelson, Katrina Ingram, Duncan MacIntosh, Darren Abramson,
Letitia Meynell, Sue Sherwin, Richmond Campbell, Ian Brooks, Jenna Donohue, William
Cochran, Jeff Behrends, Selim Berker, and Marc-Kevin Daoust. This work was supported by a
Banting Postdoctoral Fellowship from the Social Sciences and Humanities Research Council of
Canada and an Honorary Research Fellowship from the University of Sheffield. The lands on
which I wrote this essay are the traditional territories of the Mi’kmaq, Mississauga, and
Massachusett peoples.